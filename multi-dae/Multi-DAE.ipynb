{"cells":[{"cell_type":"markdown","metadata":{"id":"sQG9hL8-UQUP"},"source":["# Multi-DAE\n","\n","- [Variational Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1802.05814)에서 제안된 Multi-DAE 기반의 협업 필터링을 구현해보도록 하겠습니다. \n","- 다양한 Auto-Encoder 기반의 협업필터링이 제안된 이후에, 가장 강력하다고 평가받는 DAE 기반의 협업 필터링을 이해하는 시간을 갖도록 하겠습니다.\n","\n","- [코드](https://github.com/younggyoseo/vae-cf-pytorch)를 기반으로 작성되었습니다. "]},{"cell_type":"markdown","metadata":{"id":"J7CfnRw7U59C"},"source":["## 1. 초기 세팅"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20039,"status":"ok","timestamp":1647338351940,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"EWWEf1mPKdnX","outputId":"c2ab2ddf-9a02-4bc8-8133-ff5c95f9e366"},"outputs":[],"source":["## 전처리과정에서 pandas의 버전에 다르게 동작하는 경향이 보여, 이 미션에서는 아래 버전으로 사용하도록하겠습니다.\n","# !pip install pandas==1.0.1"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bQj6k1mSbxaz"},"outputs":[],"source":["import argparse\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from scipy import sparse\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1647338362900,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"xQ3W0udmbxa3","outputId":"a711d6bb-0f42-451f-d97b-7fed34682010"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["## 각종 파라미터 세팅\n","parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n","\n","# data path\n","parser.add_argument('--data_path', type=str, default='../../input/data/train/',\n","                    help='Movielens dataset location')\n","parser.add_argument('--model_path', type=str, default='model/',\n","                    help='path to save/load the model')\n","parser.add_argument('--submit_path', type=str, default='output/',\n","                    help='path to save the submission')\n","parser.add_argument('--load_model', type=str, default='multi-dae.pt',\n","                    help='model.pt file to load the model')\n","\n","# hyper parameter\n","parser.add_argument('--lr', type=float, default=1e-4,\n","                    help='initial learning rate')\n","parser.add_argument('--wd', type=float, default=0.01,\n","                    help='weight decay coefficient')\n","parser.add_argument('--batch_size', type=int, default=500,\n","                    help='batch size')\n","parser.add_argument('--embed_dim', type=int, default=256,\n","                    help='embedding_dim')\n","parser.add_argument('--total_anneal_steps', type=int, default=200000,\n","                    help='the total number of gradient updates for annealing')\n","parser.add_argument('--anneal_cap', type=float, default=0.2,\n","                    help='largest annealing parameter')\n","\n","# etc\n","parser.add_argument('--epochs', type=int, default=200,\n","                    help='upper epoch limit')\n","parser.add_argument('--cuda', action='store_true',\n","                    help='use CUDA')\n","parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n","                    help='report interval')\n","parser.add_argument('--seed', type=int, default=42,\n","                    help='random seed')\n","\n","# 추출한 특징 정보의 속성을 저장 \n","parser.add_argument('--n_genres', type=int, default=18,\n","                    help='genres_size')\n","parser.add_argument('--n_titles', type=int, default=6806,\n","                    help='titles_size')\n","\n","args = parser.parse_args([])\n","\n","# Set the random seed manually for reproductibility.\n","torch.manual_seed(args.seed)\n","\n","#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n","if torch.cuda.is_available():\n","    args.cuda = True\n","\n","device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","device\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7o1fvXqFWE_G"},"source":["## 2. 데이터 전처리\n","\n","- 이 부분에서 진행되는 과정은 저희가 일반적으로 알고있는 MovieLens (user, item, timestamp)데이터를 전처리하는 과정입니다. 전처리 과정의 다양한 옵션들을 구성하기 위해 약간 복잡하게 되었지만, \n","- 결과적으로는, 유저들의 특정한 아이템들을 따로 분리를 해서, 그 분리된 값을 모델이 예측할 수 있냐를 확인하기 위한 전처리 과정이라고 보시면 되겠습니다.\n","- 실제로 나오는 데이터셋을 확인하면 더욱 이해가 빠를것입니다."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cgvNoy1Ybxa6"},"outputs":[],"source":["import os\n","import pandas as pd\n","from scipy import sparse\n","import numpy as np\n","\n","def get_count(tp, id):\n","    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n","    count = playcount_groupbyid.size()\n","\n","    return count\n","\n","# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상) \n","# 데이터만을 추출할 때 사용하는 함수입니다.\n","# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n","def filter_triplets(tp, min_uc=5, min_sc=0):\n","    if min_sc > 0:\n","        itemcount = get_count(tp, 'item')\n","        tp = tp[tp['item'].isin(itemcount.index[itemcount >= min_sc])]\n","\n","    if min_uc > 0:\n","        usercount = get_count(tp, 'user')\n","        tp = tp[tp['user'].isin(usercount.index[usercount >= min_uc])]\n","\n","    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n","    return tp, usercount, itemcount\n","\n","#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n","#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n","#확인하기 위함입니다.\n","def split_train_test_proportion(data, test_prop=0.2):\n","    data_grouped_by_user = data.groupby('user')\n","    tr_list, te_list = list(), list()\n","\n","    np.random.seed(args.seed)\n","    \n","    for _, group in data_grouped_by_user:\n","        n_items_u = len(group)\n","        \n","        if n_items_u >= 5:\n","            idx = np.zeros(n_items_u, dtype='bool')\n","            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n","\n","            tr_list.append(group[np.logical_not(idx)])\n","            te_list.append(group[idx])\n","        \n","        else:\n","            tr_list.append(group)\n","    \n","    data_tr = pd.concat(tr_list)\n","    data_te = pd.concat(te_list)\n","\n","    return data_tr, data_te\n","\n","\n","def numerize(tp, profile2id, show2id):\n","    uid = tp['user'].apply(lambda x: profile2id[x])\n","    sid = tp['item'].apply(lambda x: show2id[x])\n","    \n","    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"]},{"cell_type":"markdown","metadata":{},"source":["## Modeling 예시"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uid</th>\n","      <th>sid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   uid  sid\n","0    0    4\n","1    1    5\n","2    2    6"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["item_df = pd.DataFrame(data={'uid': [0,1,2], 'sid': [4,5,6]}, columns=['uid', 'sid'])\n","item_df"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["<5x6807 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 3 stored elements in Compressed Sparse Row format>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["rows, cols = item_df['uid'], item_df['sid']\n","data = sparse.csr_matrix((np.ones_like(rows),\n","                                 (rows, cols)), dtype='float64',\n","                                 shape = (5,6807)) # shape=(n_users, self.n_items)\n","data\n","# shape : 길이를늘려주구나..."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["[0, 1, 2, 3, 4]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["e_idxlist = list(range(data.shape[0]))\n","e_idxlist"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(2, 6807)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["data = data[e_idxlist[0:2]]\n","data.shape"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["<1x6807 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 1 stored elements in Compressed Sparse Row format>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data[0]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# a = torch.FloatTensor(data.toarray())\n","# b = torch.LongTensor(np.array([list(genre_arr)] * (50)))\n","# c = torch.LongTensor(np.array([list(title_arr)] * (50)))\n","# torch.cat((a,b,c),0).shape"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["a = torch.tensor([[1]*10])\n","data = torch.FloatTensor(data.toarray())"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["a = nn.Embedding(num_embeddings=data.shape[0], embedding_dim=10)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["2"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["data.shape[0]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# a = a(torch.tensor([4,1,2,3,4]))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# data.shape\n","# a.shape"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# A = torch.cat([data, a,a], 0)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# A.split(data.shape[0], 0)/"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# a.shape"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# A = torch.cat((a, data,a), 0)\n","# # B = A.split([a, data, a], 0)\n","# # B\n","# A"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2812,"status":"ok","timestamp":1647338365706,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"fVFoRHrmVQsp","outputId":"d742d219-96a0-4334-afff-685a368ec622"},"outputs":[{"name":"stdout","output_type":"stream","text":["Load and Preprocess Movielens dataset\n"]}],"source":["print(\"Load and Preprocess Movielens dataset\")\n","# Load Data\n","DATA_DIR = args.data_path\n","raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n","year_data = pd.read_csv(os.path.join(DATA_DIR, 'years.tsv'), sep='\\t')\n","writer_data = pd.read_csv(os.path.join(DATA_DIR, 'writers.tsv'), sep='\\t')\n","title_data = pd.read_csv(os.path.join(DATA_DIR, 'titles.tsv'), sep='\\t')\n","genre_data = pd.read_csv(os.path.join(DATA_DIR, 'genres.tsv'), sep='\\t')\n","director_data = pd.read_csv(os.path.join(DATA_DIR, 'directors.tsv'), sep='\\t')\n","# print(\"장르 데이터\\n\", genre_data.head())\n","# print(\"제목 데이터\\n\", genre_data.head())\n","\n","# Filter Data\n","raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=0)\n","#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n","# print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data.head())\n","\n","# print(\"유저별 리뷰수\\n\",user_activity.head())\n","# print(\"아이템별 리뷰수\\n\",item_popularity.head())"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# 추출한 특징 정보의 속성을 저장 \n","# genre_data['genre'].nunique()\n","# title_data['title'].nunique()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1647338365706,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"7T1dTsWUrffP","outputId":"68476060-3cf6-473e-f21c-05e9cda5bdb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["(BEFORE) unique_uid: Int64Index([11, 14, 18, 25, 31], dtype='int64', name='user')\n","(AFTER) unique_uid: Int64Index([81259, 11986, 67552, 127325, 115853], dtype='int64', name='user')\n","훈련 데이터에 사용될 사용자 수: 25088\n","검증 데이터에 사용될 사용자 수: 3136\n","테스트 데이터에 사용될 사용자 수: 3136\n"]}],"source":["# Shuffle User Indices\n","unique_uid = user_activity.index\n","print(\"(BEFORE) unique_uid:\",unique_uid[:5])\n","np.random.seed(args.seed)\n","idx_perm = np.random.permutation(unique_uid.size)\n","unique_uid = unique_uid[idx_perm]\n","print(\"(AFTER) unique_uid:\",unique_uid[:5])\n","\n","n_users = unique_uid.size #31360\n","n_heldout_users = int(0.1 * n_users)\n","\n","\n","# Split Train/Validation/Test User Indices\n","tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n","vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n","te_users = unique_uid[(n_users - n_heldout_users):]\n","\n","#주의: 데이터의 수가 아닌 사용자의 수입니다!\n","print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n","print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n","print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["raw_data = pd.merge(raw_data,genre_data, on = 'item').drop_duplicates(['user','item'])\n","raw_data = pd.merge(raw_data,title_data, on = 'item').sort_values('user').reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30590,"status":"ok","timestamp":1647338396290,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"3yBsRCRqtPz6","outputId":"c1dcf49a-a33d-482e-f321-db4fb2cacb1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Done!\n"]}],"source":["##훈련 데이터에 해당하는 아이템들\n","#Train에는 전체 데이터를 사용합니다.\n","raw_data = pd.merge(raw_data,genre_data, on = 'item').drop_duplicates(['user','item'])\n","raw_data = pd.merge(raw_data,title_data, on = 'item').sort_values('user').reset_index(drop=True)\n","\n","train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n","\n","##아이템 ID, unique_uid는 위에 따로 init돼있음\n","unique_sid = pd.unique(train_plays['item'])\n","# unique_gid = pd.unique(genre_data['genre'])\n","# unique_tid = pd.unique(title_data['title'])\n","\n","show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n","profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n","# genre2id = dict((gid, i) for (i, gid) in enumerate(unique_gid))\n","# title2id = dict((tid, i) for (i, tid) in enumerate(unique_tid))\n","\n","pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n","\n","if not os.path.exists(pro_dir):\n","    os.makedirs(pro_dir)\n","\n","with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n","    for sid in unique_sid:\n","        f.write('%s\\n' % sid)\n","\n","#Validation과 Test에는 input으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다.\n","vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n","vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n","vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n","\n","test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n","test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n","test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n","\n","\n","train_data = numerize(train_plays, profile2id, show2id)\n","train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n","\n","\n","vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n","vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n","\n","\n","vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n","vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n","\n","\n","test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n","test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n","\n","\n","test_data_te = numerize(test_plays_te, profile2id, show2id)\n","test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n","\n","\n","print(\"Done!\")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1647338396291,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"jkdg2OkjqVUM","outputId":"d9e0a171-95e1-4dd0-f271-6988fcc7b695"},"outputs":[{"name":"stdout","output_type":"stream","text":["     uid  sid\n","0  13266    0\n","1  13266    1\n","2  13266    2\n","3  13266    3\n","4  13266    4\n","(414699, 2)\n","(102105, 2)\n","        uid   sid\n","2133  28125   237\n","2134  28125   252\n","2135  28125   583\n","2137  28125   735\n","2138  28125  1226\n","        uid  sid\n","2132  28125  192\n","2136  28125  144\n","2142  28125  464\n","2144  28125  175\n","2150  28125  165\n","        uid   sid\n","1514  30380   150\n","1515  30380   262\n","1516  30380    65\n","1518  30380   700\n","1520  30380  2927\n","        uid   sid\n","1517  30380   464\n","1519  30380  2031\n","1526  30380    18\n","1531  30380   485\n","1533  30380  3837\n"]}],"source":["#데이터 셋 확인\n","print(train_data.head())\n","print(vad_data_tr.shape)\n","print(vad_data_te.shape)\n","print(vad_data_tr.head())\n","print(vad_data_te.head())\n","print(test_data_tr.head())\n","print(test_data_te.head())"]},{"cell_type":"markdown","metadata":{},"source":["## Genre, Title Matrix(Array)\n","- 장르데이터 to_dict\n","- 그전에 그 순서맞는 아이템 배열을 데이터프레임으로하고 \n","- 그 컬럼을 매칭시키는 새 컬럼 생성하고 그걸 배열로 만들면 끝"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["6807"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["pro_dir = args.data_path + '/pro_sg'\n","unique_sid = list()\n","with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n","    for line in f:\n","        unique_sid.append(line.strip())\n","# unique_sid = le.fit_transform(unique_sid)\n","len(unique_sid)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["genre_data['item']  = genre_data['item'].astype(str)\n","title_data['item']  = title_data['item'].astype(str)\n","genre_target = genre_data.drop_duplicates('item').set_index('item').to_dict()['genre']\n","title_target = title_data.set_index('item').to_dict()['title']"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["item_df = pd.DataFrame(unique_sid, columns = ['item'])\n","genre_arr = le.fit_transform(item_df['item'].map(genre_target).values)\n","title_arr = le.fit_transform(item_df['item'].map(title_target).values)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["(3, 6807)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["np.stack([genre_arr, genre_arr, genre_arr], 0).shape\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, ..., 0, 4, 4],\n","       [0, 0, 0, ..., 0, 4, 4],\n","       [0, 0, 0, ..., 0, 4, 4],\n","       ...,\n","       [0, 0, 0, ..., 0, 4, 4],\n","       [0, 0, 0, ..., 0, 4, 4],\n","       [0, 0, 0, ..., 0, 4, 4]])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["np.array([list(genre_arr)] * 500)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["6806"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# 장르가 잘 들어갔는지 확인\n","pd.DataFrame(genre_arr)[0].nunique()\n","pd.DataFrame(title_arr)[0].nunique()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["array([4724, 3006, 5677, ...,  187, 4288, 4516])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["title_arr"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SMiq9leyWWL1"},"source":["## 3. 데이터 로더 설정"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"nxUADr9ibxa8"},"outputs":[],"source":["\n","class DataLoader():\n","    '''\n","    Load Movielens dataset\n","    '''\n","    def __init__(self, path):\n","        \n","        self.pro_dir = os.path.join(path, 'pro_sg')\n","        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist.\"\n","\n","        self.n_items = self.load_n_items()\n","    \n","    def load_data(self, datatype='train'):\n","        if datatype == 'train':\n","            return self._load_train_data()\n","        elif datatype == 'validation':\n","            return self._load_tr_te_data(datatype)\n","        elif datatype == 'test':\n","            return self._load_tr_te_data(datatype)\n","        else:\n","            raise ValueError(\"datatype should be in [train, validation, test]\")\n","        \n","    def load_n_items(self):\n","        unique_sid = list()\n","        with open(os.path.join(self.pro_dir, 'unique_sid.txt'), 'r') as f:\n","            for line in f:\n","                unique_sid.append(line.strip())\n","        n_items = len(unique_sid)\n","        return n_items\n","    \n","    def _load_train_data(self):\n","        path = os.path.join(self.pro_dir, 'train.csv')\n","        \n","        tp = pd.read_csv(path)\n","        n_users = tp['uid'].max() + 1\n","\n","        rows, cols = tp['uid'], tp['sid']\n","        data = sparse.csr_matrix((np.ones_like(rows),\n","                                 (rows, cols)), dtype='float64',\n","                                 shape=(n_users, self.n_items))\n","        return data\n","    \n","    def _load_tr_te_data(self, datatype='test'):\n","        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n","        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n","        tp_tr = pd.read_csv(tr_path)\n","        tp_te = pd.read_csv(te_path)\n","        \n","        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n","        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n","\n","        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n","        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n","\n","        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n","                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n","        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n","                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n","        return data_tr, data_te"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6FHhwKqXWaUZ"},"source":["## 4. 모델정의\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([0, 0, 0,  ..., 0, 4, 4]), tensor([0, 0, 0,  ..., 0, 4, 4]))"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.LongTensor(np.array(list(genre_arr)))\n","b = torch.LongTensor(np.array(list(genre_arr)))\n","# b = nn.Embedding(num_embeddings=18, embedding_dim=9)\n","# b(a).squeeze(-1).shape\n","# print(b(a).squeeze(0).shape)\n","# num_embeddings : 장르의 유니크한 크기 (임베딩을 위한 사전의 크기\n","c = torch.cat((a,b), 0)\n","c.split(a.shape[0],0)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"QYlGPJTYU0ii"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import numpy as np\n","\n","\n","#이미 완성된 MultiDAE의 코드를 참고하여 그 아래 MultiVAE의 코드를 완성해보세요!\n","class MultiDAE(nn.Module):\n","    \"\"\"\n","    Container module for Multi-DAE.\n","\n","    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n","    See Variational Autoencoders for Collaborative Filtering\n","    https://arxiv.org/abs/1802.05814\n","    \"\"\"\n","\n","    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n","        super(MultiDAE, self).__init__()\n","        # Embedding 추가\n","        # self.genre_embeddig = nn.Embedding(num_embeddings=19, embedding_dim=1)\n","        # self.title_embeddig = nn.Embedding(num_embeddings=19, embedding_dim=1)\n","        \n","        self.p_dims = p_dims\n","        if q_dims:\n","            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n","            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n","            self.q_dims = q_dims\n","        else:\n","            self.q_dims = p_dims[::-1]\n","            \n","        # hidden dim change\n","        self.p_dims[1] *= 2\n","        \n","        self.dims = self.q_dims + self.p_dims[1:]\n","        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n","        self.drop = nn.Dropout(dropout)\n","        \n","        self.init_weights()\n","    \n","    def forward(self, input, feats):\n","        h = F.normalize(input)\n","        # print(h.shape)\n","        genre_embedding_mlp = F.normalize(feats[0])\n","        # print(genre_embedding_mlp.shape)\n","        # title_embedding_mlp = self.title_embeddig(feats[1]).squeeze()\n","        # print(title_embedding_mlp.shape)\n","        \n","        # torch cat 이용해서 밑으로 붙이기\n","        h = torch.cat((genre_embedding_mlp, h), 0) \n","        # print(h.shape)\n","        h = self.drop(h)\n","\n","        for i, layer in enumerate(self.layers):\n","            h = layer(h)\n","            if i != len(self.layers) - 1:\n","                h = torch.tanh(h)\n","        \n","        # 결과값\n","        reconstructed_genre, reconstructed_h = h.split(input.shape[0], 0) \n","        \n","        return reconstructed_h\n","\n","    def init_weights(self):\n","        for layer in self.layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","\n","\n","\n","class MultiVAE(nn.Module):\n","    \"\"\"\n","    Container module for Multi-VAE.\n","\n","    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n","    See Variational Autoencoders for Collaborative Filtering\n","    https://arxiv.org/abs/1802.05814\n","    \"\"\"\n","\n","    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n","        super(MultiVAE, self).__init__()\n","        self.p_dims = p_dims\n","        if q_dims:\n","            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n","            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n","            self.q_dims = q_dims\n","        else:\n","            self.q_dims = p_dims[::-1]\n","\n","        # Last dimension of q- network is for mean and variance\n","        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n","        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n","        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n","        \n","        self.drop = nn.Dropout(dropout)\n","        self.init_weights()\n","    \n","    def forward(self, input):\n","        mu, logvar = self.encode(input)\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","    \n","    def encode(self, input):\n","        h = F.normalize(input)\n","        h = self.drop(h)\n","        \n","        for i, layer in enumerate(self.q_layers):\n","            h = layer(h)\n","            if i != len(self.q_layers) - 1:\n","                h = torch.tanh(h)\n","            else:\n","                mu = h[:, :self.q_dims[-1]]\n","                logvar = h[:, self.q_dims[-1]:]\n","        return mu, logvar\n","\n","    def reparameterize(self, mu, logvar):\n","        if self.training:\n","            std = torch.exp(0.5 * logvar)\n","            eps = torch.randn_like(std)\n","            return eps.mul(std).add_(mu)\n","        else:\n","            return mu\n","    \n","    def decode(self, z):\n","        h = z\n","        for i, layer in enumerate(self.p_layers):\n","            h = layer(h)\n","            if i != len(self.p_layers) - 1:\n","                h = torch.tanh(h)\n","        return h\n","\n","    def init_weights(self):\n","        for layer in self.q_layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","        \n","        for layer in self.p_layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","\n","\n","\n","def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n","    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n","    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n","\n","    return BCE + anneal * KLD\n","\n","def loss_function_dae(recon_x, x):\n","    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n","    return BCE"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>item</th>\n","      <th>genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>318</td>\n","      <td>Crime</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2571</td>\n","      <td>Action</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2959</td>\n","      <td>Action</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>296</td>\n","      <td>Comedy</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>356</td>\n","      <td>Comedy</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15925</th>\n","      <td>73106</td>\n","      <td>Comedy</td>\n","    </tr>\n","    <tr>\n","      <th>15926</th>\n","      <td>109850</td>\n","      <td>Action</td>\n","    </tr>\n","    <tr>\n","      <th>15929</th>\n","      <td>8605</td>\n","      <td>Action</td>\n","    </tr>\n","    <tr>\n","      <th>15931</th>\n","      <td>3689</td>\n","      <td>Comedy</td>\n","    </tr>\n","    <tr>\n","      <th>15932</th>\n","      <td>8130</td>\n","      <td>Documentary</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6807 rows × 2 columns</p>\n","</div>"],"text/plain":["         item        genre\n","0         318        Crime\n","2        2571       Action\n","5        2959       Action\n","9         296       Comedy\n","13        356       Comedy\n","...       ...          ...\n","15925   73106       Comedy\n","15926  109850       Action\n","15929    8605       Action\n","15931    3689       Comedy\n","15932    8130  Documentary\n","\n","[6807 rows x 2 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["a = [[1,2,3,4]]\n","genre_data.drop_duplicates(subset = ['item'])"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["300"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["torch.LongTensor(np.array([list(genre_arr)] * (50))).shape\n","a = torch.Tensor([1,2,3])\n","b = torch.Tensor([3,2,3])\n","torch.cat((a,b), -1)\n","500-200"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","4\n","7\n"]}],"source":["for i in range(1,10,3):\n","    print(i)"]},{"cell_type":"markdown","metadata":{},"source":["## Train, Evaluation"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"7nEfVTktbxa8"},"outputs":[],"source":["def sparse2torch_sparse(data):\n","    \"\"\"\n","    Convert scipy sparse matrix to torch sparse tensor with L2 Normalization\n","    This is much faster than naive use of torch.FloatTensor(data.toarray())\n","    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n","    \"\"\"\n","    samples = data.shape[0]\n","    features = data.shape[1]\n","    coo_data = data.tocoo()\n","    indices = torch.LongTensor([coo_data.row, coo_data.col])\n","    row_norms_inv = 1 / np.sqrt(data.sum(1))\n","    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n","    values = np.array([row2val[r] for r in coo_data.row])\n","    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n","    return t\n","\n","def naive_sparse2tensor(data):\n","    return torch.FloatTensor(data.toarray())\n","\n","\n","def train(model, criterion, optimizer, is_VAE = False):\n","    # Turn on training mode\n","    model.train()\n","    train_loss = 0.0\n","    start_time = time.time()\n","    global update_count\n","\n","    np.random.shuffle(idxlist)\n","    \n","    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n","        end_idx = min(start_idx + args.batch_size, N)\n","        # train data -> global 변수\n","        data = train_data[idxlist[start_idx:end_idx]]\n","        data = naive_sparse2tensor(data).to(device)\n","        # Features 추가 필요\n","        feat1 = torch.FloatTensor(np.array([list(genre_arr)] * (end_idx - start_idx))).to(device)\n","        # feat2 = torch.LongTensor(np.array(list(title_arr))).to(device)\n","        \n","        optimizer.zero_grad()\n","\n","        if is_VAE:\n","          if args.total_anneal_steps > 0:\n","            anneal = min(args.anneal_cap, \n","                            1. * update_count / args.total_anneal_steps)\n","          else:\n","              anneal = args.anneal_cap\n","\n","          optimizer.zero_grad()\n","          recon_batch, mu, logvar = model(data)\n","          \n","          loss = criterion(recon_batch, data, mu, logvar, anneal)\n","        else:\n","          recon_batch = model(data, [feat1])\n","          loss = criterion(recon_batch, data)\n","\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","\n","        update_count += 1\n","\n","        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n","                    'loss {:4.2f}'.format(\n","                        epoch, batch_idx, len(range(0, N, args.batch_size)),\n","                        elapsed * 1000 / args.log_interval,\n","                        train_loss / args.log_interval))\n","            \n","\n","            start_time = time.time()\n","            train_loss = 0.0\n","\n","\n","def evaluate(model, criterion, data_tr, data_te, is_VAE=False):\n","    # Turn on evaluation mode\n","    model.eval()\n","    total_loss = 0.0\n","    global update_count\n","    e_idxlist = list(range(data_tr.shape[0]))\n","    e_N = data_tr.shape[0]\n","    n100_list = []\n","    r10_list = []\n","    r20_list = []\n","    r50_list = []\n","    \n","    with torch.no_grad():\n","        for start_idx in range(0, e_N, args.batch_size):\n","            end_idx = min(start_idx + args.batch_size, e_N)\n","            data = data_tr[e_idxlist[start_idx:end_idx]]\n","            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n","            feat1 = torch.FloatTensor(np.array([list(genre_arr)] * (end_idx - start_idx))).to(device)\n","            # feat2 = torch.LongTensor(np.array(list(title_arr))).to(device)\n","\n","            data_tensor = naive_sparse2tensor(data).to(device)\n","            if is_VAE :\n","              \n","              if args.total_anneal_steps > 0:\n","                  anneal = min(args.anneal_cap, \n","                                1. * update_count / args.total_anneal_steps)\n","              else:\n","                  anneal = args.anneal_cap\n","\n","              recon_batch, mu, logvar = model(data_tensor)\n","\n","              loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n","\n","            else :\n","              recon_batch = model(data_tensor, [feat1])\n","              loss = criterion(recon_batch, data_tensor)\n","\n","\n","            total_loss += loss.item()\n","\n","            # Exclude examples from training set\n","            recon_batch = recon_batch.cpu().numpy()\n","            recon_batch[data.nonzero()] = -np.inf\n","\n","            n100 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 100)\n","            r10 = Recall_at_k_batch(recon_batch, heldout_data, 10)\n","            r20 = Recall_at_k_batch(recon_batch, heldout_data, 20)\n","            r50 = Recall_at_k_batch(recon_batch, heldout_data, 50)\n","\n","            n100_list.append(n100)\n","            r10_list.append(r10)\n","            r20_list.append(r20)\n","            r50_list.append(r50)\n"," \n","    total_loss /= len(range(0, e_N, args.batch_size))\n","    n100_list = np.concatenate(n100_list)\n","    r10_list = np.concatenate(r10_list)\n","    r20_list = np.concatenate(r20_list)\n","    r50_list = np.concatenate(r50_list)\n","\n","    return total_loss, np.mean(n100_list), np.mean(r10_list), np.mean(r20_list), np.mean(r50_list)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JOsCJbb_X9gl"},"source":["## 5. Metric 정의"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: bottleneck in /opt/conda/lib/python3.8/site-packages (1.3.5)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from bottleneck) (1.19.2)\n"]}],"source":["!pip install bottleneck"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"zxNtit6vbxa-"},"outputs":[],"source":["import bottleneck as bn\n","import numpy as np\n","\n","def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n","    '''\n","    Normalized Discounted Cumulative Gain@k for binary relevance\n","    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n","    '''\n","    batch_users = X_pred.shape[0]\n","    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n","    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n","                       idx_topk_part[:, :k]]\n","    idx_part = np.argsort(-topk_part, axis=1)\n","\n","    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n","\n","    tp = 1. / np.log2(np.arange(2, k + 2))\n","\n","    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n","                         idx_topk].toarray() * tp).sum(axis=1)\n","    IDCG = np.array([(tp[:min(n, k)]).sum()\n","                     for n in heldout_batch.getnnz(axis=1)])\n","    return DCG / IDCG\n","\n","\n","def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n","    batch_users = X_pred.shape[0]\n","\n","    idx = bn.argpartition(-X_pred, k, axis=1)\n","    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n","    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n","\n","    X_true_binary = (heldout_batch > 0).toarray()\n","    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n","        np.float32)\n","    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n","    return recall"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cDD7lD7sHcnH"},"source":["## 6. MultiDAE 테스트"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["if not os.path.exists(args.model_path):\n","    os.makedirs(args.model_path)\n","\n","dae_path = args.model_path + \"multi-dae.pt\"\n","vae_path = args.model_path + \"multi-vae.pt\""]},{"cell_type":"code","execution_count":44,"metadata":{"id":"WLYyTwToX4fm"},"outputs":[],"source":["\n","###############################################################################\n","# Load data\n","###############################################################################\n","\n","loader = DataLoader(args.data_path)\n","\n","n_items = loader.load_n_items()\n","train_data = loader.load_data('train')\n","vad_data_tr, vad_data_te = loader.load_data('validation')\n","test_data_tr, test_data_te = loader.load_data('test')\n","\n","N = train_data.shape[0]\n","idxlist = list(range(N))\n","\n","###############################################################################\n","# Build the model\n","###############################################################################\n","\n","p_dims = [100, 1200, n_items]\n","model = MultiDAE(p_dims).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n","criterion = loss_function_dae\n","\n","###############################################################################\n","# Training code\n","###############################################################################\n","\n","best_r10 = -np.inf  #best_n100 = -np.inf\n","update_count = 0"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["25088\n"]},{"data":{"text/plain":["(3136, 6807)"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["print(N)\n","vad_data_tr.shape"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51906,"status":"ok","timestamp":1647338459035,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"6rOEDs2Lbxa-","outputId":"929ac77e-b755-4b1f-9479-5ae2ee98780f"},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 18.80s | valid loss 1041.16 | n100 0.267 | r10 0.208 | r20 0.193 | r50 0.240\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 18.41s | valid loss 1026.23 | n100 0.269 | r10 0.211 | r20 0.193 | r50 0.243\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 18.56s | valid loss 1022.43 | n100 0.269 | r10 0.211 | r20 0.194 | r50 0.242\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 18.44s | valid loss 1018.10 | n100 0.275 | r10 0.217 | r20 0.200 | r50 0.247\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 18.33s | valid loss 1002.05 | n100 0.303 | r10 0.247 | r20 0.225 | r50 0.275\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 18.29s | valid loss 990.51 | n100 0.320 | r10 0.256 | r20 0.238 | r50 0.291\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 18.34s | valid loss 986.55 | n100 0.324 | r10 0.263 | r20 0.243 | r50 0.295\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 18.43s | valid loss 982.25 | n100 0.334 | r10 0.275 | r20 0.252 | r50 0.304\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 18.44s | valid loss 976.89 | n100 0.343 | r10 0.281 | r20 0.259 | r50 0.311\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 18.43s | valid loss 974.62 | n100 0.345 | r10 0.283 | r20 0.261 | r50 0.313\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  11 | time: 18.41s | valid loss 972.61 | n100 0.350 | r10 0.289 | r20 0.265 | r50 0.317\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  12 | time: 18.39s | valid loss 969.82 | n100 0.357 | r10 0.297 | r20 0.272 | r50 0.324\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  13 | time: 18.38s | valid loss 967.21 | n100 0.362 | r10 0.301 | r20 0.275 | r50 0.328\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  14 | time: 18.45s | valid loss 965.26 | n100 0.365 | r10 0.305 | r20 0.279 | r50 0.331\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  15 | time: 18.46s | valid loss 962.64 | n100 0.372 | r10 0.309 | r20 0.284 | r50 0.337\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  16 | time: 18.41s | valid loss 960.55 | n100 0.375 | r10 0.312 | r20 0.286 | r50 0.340\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  17 | time: 18.35s | valid loss 959.27 | n100 0.375 | r10 0.313 | r20 0.287 | r50 0.342\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  18 | time: 18.34s | valid loss 957.95 | n100 0.378 | r10 0.318 | r20 0.291 | r50 0.344\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  19 | time: 18.37s | valid loss 956.19 | n100 0.382 | r10 0.321 | r20 0.293 | r50 0.347\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  20 | time: 18.43s | valid loss 954.44 | n100 0.385 | r10 0.323 | r20 0.296 | r50 0.350\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  21 | time: 18.40s | valid loss 953.21 | n100 0.387 | r10 0.324 | r20 0.296 | r50 0.353\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  22 | time: 18.37s | valid loss 951.92 | n100 0.390 | r10 0.326 | r20 0.298 | r50 0.354\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  23 | time: 18.36s | valid loss 950.62 | n100 0.391 | r10 0.328 | r20 0.301 | r50 0.357\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  24 | time: 18.41s | valid loss 949.60 | n100 0.392 | r10 0.330 | r20 0.302 | r50 0.358\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  25 | time: 18.41s | valid loss 948.80 | n100 0.393 | r10 0.328 | r20 0.301 | r50 0.360\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  26 | time: 18.40s | valid loss 948.24 | n100 0.394 | r10 0.330 | r20 0.302 | r50 0.360\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  27 | time: 18.29s | valid loss 947.70 | n100 0.395 | r10 0.329 | r20 0.303 | r50 0.362\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  28 | time: 18.35s | valid loss 947.22 | n100 0.395 | r10 0.331 | r20 0.303 | r50 0.362\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  29 | time: 18.43s | valid loss 946.80 | n100 0.396 | r10 0.331 | r20 0.304 | r50 0.363\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  30 | time: 18.43s | valid loss 946.31 | n100 0.397 | r10 0.331 | r20 0.304 | r50 0.364\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  31 | time: 18.42s | valid loss 945.89 | n100 0.398 | r10 0.333 | r20 0.305 | r50 0.365\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  32 | time: 18.37s | valid loss 945.45 | n100 0.399 | r10 0.334 | r20 0.306 | r50 0.366\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  33 | time: 18.48s | valid loss 944.99 | n100 0.400 | r10 0.334 | r20 0.307 | r50 0.366\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  34 | time: 18.40s | valid loss 944.50 | n100 0.400 | r10 0.334 | r20 0.307 | r50 0.367\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  35 | time: 18.42s | valid loss 944.01 | n100 0.401 | r10 0.334 | r20 0.308 | r50 0.368\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  36 | time: 18.37s | valid loss 943.56 | n100 0.402 | r10 0.335 | r20 0.310 | r50 0.369\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  37 | time: 18.50s | valid loss 943.11 | n100 0.403 | r10 0.336 | r20 0.310 | r50 0.370\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  38 | time: 18.40s | valid loss 942.61 | n100 0.404 | r10 0.337 | r20 0.311 | r50 0.371\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  39 | time: 18.48s | valid loss 942.19 | n100 0.405 | r10 0.338 | r20 0.311 | r50 0.372\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  40 | time: 18.33s | valid loss 941.79 | n100 0.406 | r10 0.337 | r20 0.312 | r50 0.372\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  41 | time: 18.35s | valid loss 941.31 | n100 0.406 | r10 0.339 | r20 0.313 | r50 0.372\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  42 | time: 18.40s | valid loss 940.91 | n100 0.408 | r10 0.340 | r20 0.314 | r50 0.373\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  43 | time: 18.37s | valid loss 940.42 | n100 0.409 | r10 0.341 | r20 0.314 | r50 0.375\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  44 | time: 18.43s | valid loss 940.04 | n100 0.410 | r10 0.345 | r20 0.316 | r50 0.375\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  45 | time: 18.43s | valid loss 939.62 | n100 0.411 | r10 0.345 | r20 0.317 | r50 0.376\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  46 | time: 18.34s | valid loss 939.16 | n100 0.411 | r10 0.343 | r20 0.316 | r50 0.376\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  47 | time: 18.24s | valid loss 938.78 | n100 0.411 | r10 0.345 | r20 0.317 | r50 0.376\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  48 | time: 18.43s | valid loss 938.37 | n100 0.412 | r10 0.346 | r20 0.318 | r50 0.378\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  49 | time: 18.48s | valid loss 938.06 | n100 0.413 | r10 0.348 | r20 0.320 | r50 0.379\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  50 | time: 18.44s | valid loss 937.71 | n100 0.414 | r10 0.347 | r20 0.320 | r50 0.379\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  51 | time: 18.44s | valid loss 937.40 | n100 0.414 | r10 0.347 | r20 0.320 | r50 0.379\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  52 | time: 18.43s | valid loss 937.05 | n100 0.414 | r10 0.348 | r20 0.321 | r50 0.380\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  53 | time: 18.40s | valid loss 936.78 | n100 0.415 | r10 0.351 | r20 0.321 | r50 0.380\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  54 | time: 18.52s | valid loss 936.45 | n100 0.416 | r10 0.349 | r20 0.322 | r50 0.381\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  55 | time: 18.47s | valid loss 936.12 | n100 0.416 | r10 0.350 | r20 0.322 | r50 0.381\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  56 | time: 18.43s | valid loss 935.80 | n100 0.416 | r10 0.351 | r20 0.322 | r50 0.382\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  57 | time: 18.43s | valid loss 935.49 | n100 0.417 | r10 0.350 | r20 0.323 | r50 0.382\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  58 | time: 18.38s | valid loss 935.23 | n100 0.418 | r10 0.354 | r20 0.323 | r50 0.383\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  59 | time: 18.45s | valid loss 934.91 | n100 0.418 | r10 0.352 | r20 0.323 | r50 0.383\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  60 | time: 18.42s | valid loss 934.56 | n100 0.419 | r10 0.354 | r20 0.325 | r50 0.385\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  61 | time: 18.41s | valid loss 934.31 | n100 0.420 | r10 0.354 | r20 0.325 | r50 0.385\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  62 | time: 18.44s | valid loss 933.97 | n100 0.421 | r10 0.356 | r20 0.326 | r50 0.386\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  63 | time: 18.40s | valid loss 933.67 | n100 0.421 | r10 0.354 | r20 0.324 | r50 0.386\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  64 | time: 18.51s | valid loss 933.38 | n100 0.423 | r10 0.357 | r20 0.327 | r50 0.387\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  65 | time: 18.48s | valid loss 933.09 | n100 0.423 | r10 0.356 | r20 0.325 | r50 0.387\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  66 | time: 18.51s | valid loss 932.81 | n100 0.423 | r10 0.357 | r20 0.328 | r50 0.387\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  67 | time: 18.43s | valid loss 932.51 | n100 0.423 | r10 0.355 | r20 0.327 | r50 0.387\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  68 | time: 18.38s | valid loss 932.32 | n100 0.425 | r10 0.361 | r20 0.329 | r50 0.388\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  69 | time: 18.46s | valid loss 932.08 | n100 0.425 | r10 0.361 | r20 0.330 | r50 0.388\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  70 | time: 18.45s | valid loss 931.80 | n100 0.426 | r10 0.360 | r20 0.330 | r50 0.389\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  71 | time: 18.53s | valid loss 931.56 | n100 0.425 | r10 0.359 | r20 0.330 | r50 0.389\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  72 | time: 18.42s | valid loss 931.31 | n100 0.426 | r10 0.362 | r20 0.331 | r50 0.390\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  73 | time: 18.44s | valid loss 931.05 | n100 0.426 | r10 0.361 | r20 0.330 | r50 0.390\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  74 | time: 18.50s | valid loss 930.82 | n100 0.427 | r10 0.358 | r20 0.330 | r50 0.391\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  75 | time: 18.37s | valid loss 930.62 | n100 0.428 | r10 0.361 | r20 0.331 | r50 0.391\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  76 | time: 18.45s | valid loss 930.37 | n100 0.427 | r10 0.361 | r20 0.331 | r50 0.392\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  77 | time: 18.35s | valid loss 930.19 | n100 0.428 | r10 0.361 | r20 0.331 | r50 0.393\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  78 | time: 18.47s | valid loss 929.98 | n100 0.429 | r10 0.362 | r20 0.333 | r50 0.392\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  79 | time: 18.31s | valid loss 929.80 | n100 0.428 | r10 0.361 | r20 0.333 | r50 0.393\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  80 | time: 18.47s | valid loss 929.59 | n100 0.429 | r10 0.362 | r20 0.333 | r50 0.392\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  81 | time: 18.42s | valid loss 929.41 | n100 0.429 | r10 0.363 | r20 0.333 | r50 0.393\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  82 | time: 18.33s | valid loss 929.22 | n100 0.429 | r10 0.361 | r20 0.333 | r50 0.393\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  83 | time: 18.44s | valid loss 929.07 | n100 0.430 | r10 0.364 | r20 0.333 | r50 0.394\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  84 | time: 18.45s | valid loss 928.87 | n100 0.430 | r10 0.364 | r20 0.335 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  85 | time: 18.31s | valid loss 928.72 | n100 0.430 | r10 0.362 | r20 0.334 | r50 0.394\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  86 | time: 18.41s | valid loss 928.54 | n100 0.430 | r10 0.364 | r20 0.335 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  87 | time: 18.44s | valid loss 928.38 | n100 0.431 | r10 0.365 | r20 0.335 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  88 | time: 18.41s | valid loss 928.23 | n100 0.431 | r10 0.365 | r20 0.335 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  89 | time: 18.44s | valid loss 927.97 | n100 0.431 | r10 0.363 | r20 0.335 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  90 | time: 18.41s | valid loss 927.95 | n100 0.432 | r10 0.368 | r20 0.337 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  91 | time: 18.43s | valid loss 927.74 | n100 0.431 | r10 0.364 | r20 0.336 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  92 | time: 18.50s | valid loss 927.58 | n100 0.432 | r10 0.366 | r20 0.336 | r50 0.396\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  93 | time: 18.46s | valid loss 927.44 | n100 0.432 | r10 0.369 | r20 0.337 | r50 0.396\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  94 | time: 18.39s | valid loss 927.29 | n100 0.432 | r10 0.366 | r20 0.336 | r50 0.396\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  95 | time: 18.54s | valid loss 927.16 | n100 0.433 | r10 0.365 | r20 0.336 | r50 0.396\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  96 | time: 18.37s | valid loss 927.03 | n100 0.432 | r10 0.366 | r20 0.337 | r50 0.397\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  97 | time: 18.43s | valid loss 926.90 | n100 0.433 | r10 0.365 | r20 0.337 | r50 0.397\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  98 | time: 18.33s | valid loss 926.76 | n100 0.434 | r10 0.368 | r20 0.337 | r50 0.397\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  99 | time: 18.36s | valid loss 926.58 | n100 0.432 | r10 0.364 | r20 0.335 | r50 0.397\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 100 | time: 18.49s | valid loss 926.54 | n100 0.433 | r10 0.368 | r20 0.338 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 101 | time: 18.44s | valid loss 926.36 | n100 0.433 | r10 0.365 | r20 0.336 | r50 0.397\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 102 | time: 18.35s | valid loss 926.26 | n100 0.434 | r10 0.368 | r20 0.338 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 103 | time: 18.41s | valid loss 926.12 | n100 0.434 | r10 0.367 | r20 0.338 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 104 | time: 18.40s | valid loss 926.03 | n100 0.434 | r10 0.370 | r20 0.338 | r50 0.397\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 105 | time: 18.41s | valid loss 925.88 | n100 0.434 | r10 0.366 | r20 0.337 | r50 0.397\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 106 | time: 18.60s | valid loss 925.76 | n100 0.434 | r10 0.369 | r20 0.338 | r50 0.397\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 107 | time: 18.36s | valid loss 925.66 | n100 0.435 | r10 0.367 | r20 0.338 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 108 | time: 18.41s | valid loss 925.57 | n100 0.434 | r10 0.370 | r20 0.339 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 109 | time: 18.34s | valid loss 925.46 | n100 0.434 | r10 0.369 | r20 0.339 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 110 | time: 18.38s | valid loss 925.36 | n100 0.435 | r10 0.369 | r20 0.339 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 111 | time: 18.38s | valid loss 925.24 | n100 0.435 | r10 0.370 | r20 0.339 | r50 0.399\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 112 | time: 18.52s | valid loss 925.09 | n100 0.435 | r10 0.368 | r20 0.338 | r50 0.399\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 113 | time: 18.41s | valid loss 925.04 | n100 0.435 | r10 0.370 | r20 0.339 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 114 | time: 18.43s | valid loss 924.88 | n100 0.435 | r10 0.369 | r20 0.339 | r50 0.399\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 115 | time: 18.47s | valid loss 924.82 | n100 0.436 | r10 0.371 | r20 0.341 | r50 0.399\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 116 | time: 18.36s | valid loss 924.71 | n100 0.435 | r10 0.370 | r20 0.341 | r50 0.399\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 117 | time: 18.35s | valid loss 924.59 | n100 0.436 | r10 0.371 | r20 0.340 | r50 0.399\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 118 | time: 18.44s | valid loss 924.46 | n100 0.435 | r10 0.368 | r20 0.340 | r50 0.400\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 119 | time: 18.30s | valid loss 924.42 | n100 0.436 | r10 0.371 | r20 0.341 | r50 0.400\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 120 | time: 18.42s | valid loss 924.28 | n100 0.436 | r10 0.369 | r20 0.341 | r50 0.400\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 121 | time: 18.35s | valid loss 924.24 | n100 0.436 | r10 0.370 | r20 0.341 | r50 0.400\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 122 | time: 18.44s | valid loss 924.07 | n100 0.436 | r10 0.369 | r20 0.341 | r50 0.400\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 123 | time: 18.41s | valid loss 924.00 | n100 0.437 | r10 0.372 | r20 0.342 | r50 0.400\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 124 | time: 18.39s | valid loss 923.94 | n100 0.436 | r10 0.371 | r20 0.341 | r50 0.401\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 125 | time: 18.36s | valid loss 923.78 | n100 0.436 | r10 0.369 | r20 0.342 | r50 0.401\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 126 | time: 18.40s | valid loss 923.69 | n100 0.437 | r10 0.370 | r20 0.342 | r50 0.401\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 127 | time: 18.49s | valid loss 923.66 | n100 0.437 | r10 0.371 | r20 0.342 | r50 0.401\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 128 | time: 18.40s | valid loss 923.60 | n100 0.437 | r10 0.372 | r20 0.342 | r50 0.401\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 129 | time: 18.56s | valid loss 923.44 | n100 0.437 | r10 0.371 | r20 0.342 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 130 | time: 18.43s | valid loss 923.40 | n100 0.437 | r10 0.372 | r20 0.343 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 131 | time: 18.34s | valid loss 923.27 | n100 0.437 | r10 0.370 | r20 0.342 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 132 | time: 18.38s | valid loss 923.26 | n100 0.438 | r10 0.373 | r20 0.343 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 133 | time: 18.38s | valid loss 923.11 | n100 0.437 | r10 0.372 | r20 0.341 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 134 | time: 18.21s | valid loss 922.98 | n100 0.438 | r10 0.373 | r20 0.344 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 135 | time: 18.42s | valid loss 922.95 | n100 0.438 | r10 0.372 | r20 0.343 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 136 | time: 18.32s | valid loss 922.87 | n100 0.438 | r10 0.373 | r20 0.344 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 137 | time: 18.34s | valid loss 922.76 | n100 0.439 | r10 0.375 | r20 0.343 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 138 | time: 18.38s | valid loss 922.67 | n100 0.438 | r10 0.373 | r20 0.343 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 139 | time: 18.37s | valid loss 922.70 | n100 0.438 | r10 0.374 | r20 0.345 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 140 | time: 18.34s | valid loss 922.55 | n100 0.438 | r10 0.372 | r20 0.344 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 141 | time: 18.50s | valid loss 922.50 | n100 0.439 | r10 0.373 | r20 0.345 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 142 | time: 18.38s | valid loss 922.41 | n100 0.439 | r10 0.371 | r20 0.343 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 143 | time: 18.31s | valid loss 922.31 | n100 0.439 | r10 0.373 | r20 0.343 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 144 | time: 18.35s | valid loss 922.26 | n100 0.440 | r10 0.374 | r20 0.344 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 145 | time: 18.39s | valid loss 922.19 | n100 0.440 | r10 0.374 | r20 0.344 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 146 | time: 18.34s | valid loss 922.10 | n100 0.439 | r10 0.373 | r20 0.344 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 147 | time: 18.50s | valid loss 922.03 | n100 0.440 | r10 0.374 | r20 0.345 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 148 | time: 18.39s | valid loss 921.95 | n100 0.440 | r10 0.372 | r20 0.344 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 149 | time: 18.42s | valid loss 921.84 | n100 0.439 | r10 0.373 | r20 0.344 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 150 | time: 18.47s | valid loss 921.80 | n100 0.440 | r10 0.373 | r20 0.343 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 151 | time: 18.45s | valid loss 921.78 | n100 0.439 | r10 0.374 | r20 0.344 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 152 | time: 18.45s | valid loss 921.77 | n100 0.441 | r10 0.374 | r20 0.344 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 153 | time: 18.40s | valid loss 921.57 | n100 0.439 | r10 0.373 | r20 0.344 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 154 | time: 18.37s | valid loss 921.57 | n100 0.440 | r10 0.373 | r20 0.344 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 155 | time: 18.46s | valid loss 921.51 | n100 0.441 | r10 0.375 | r20 0.345 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 156 | time: 18.44s | valid loss 921.42 | n100 0.440 | r10 0.374 | r20 0.344 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 157 | time: 18.31s | valid loss 921.41 | n100 0.440 | r10 0.375 | r20 0.344 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 158 | time: 18.40s | valid loss 921.32 | n100 0.441 | r10 0.374 | r20 0.346 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 159 | time: 18.35s | valid loss 921.28 | n100 0.441 | r10 0.375 | r20 0.347 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 160 | time: 18.42s | valid loss 921.19 | n100 0.441 | r10 0.376 | r20 0.345 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 161 | time: 18.40s | valid loss 921.14 | n100 0.441 | r10 0.376 | r20 0.346 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 162 | time: 18.43s | valid loss 921.10 | n100 0.441 | r10 0.376 | r20 0.346 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 163 | time: 18.46s | valid loss 921.03 | n100 0.441 | r10 0.374 | r20 0.345 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 164 | time: 18.49s | valid loss 920.98 | n100 0.442 | r10 0.377 | r20 0.347 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 165 | time: 18.48s | valid loss 920.93 | n100 0.441 | r10 0.376 | r20 0.346 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 166 | time: 18.33s | valid loss 920.81 | n100 0.441 | r10 0.373 | r20 0.344 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 167 | time: 18.44s | valid loss 920.80 | n100 0.441 | r10 0.377 | r20 0.347 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 168 | time: 18.39s | valid loss 920.77 | n100 0.442 | r10 0.374 | r20 0.347 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 169 | time: 18.35s | valid loss 920.65 | n100 0.441 | r10 0.374 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 170 | time: 18.42s | valid loss 920.55 | n100 0.441 | r10 0.374 | r20 0.346 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 171 | time: 18.44s | valid loss 920.59 | n100 0.442 | r10 0.375 | r20 0.347 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 172 | time: 18.50s | valid loss 920.51 | n100 0.441 | r10 0.375 | r20 0.346 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 173 | time: 18.41s | valid loss 920.47 | n100 0.442 | r10 0.376 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 174 | time: 18.39s | valid loss 920.46 | n100 0.442 | r10 0.377 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 175 | time: 18.37s | valid loss 920.35 | n100 0.443 | r10 0.378 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 176 | time: 18.53s | valid loss 920.28 | n100 0.442 | r10 0.375 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 177 | time: 18.32s | valid loss 920.26 | n100 0.442 | r10 0.378 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 178 | time: 18.39s | valid loss 920.21 | n100 0.443 | r10 0.377 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 179 | time: 18.33s | valid loss 920.16 | n100 0.442 | r10 0.377 | r20 0.346 | r50 0.405\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 180 | time: 18.39s | valid loss 920.12 | n100 0.442 | r10 0.377 | r20 0.347 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 181 | time: 18.46s | valid loss 920.05 | n100 0.443 | r10 0.377 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 182 | time: 18.42s | valid loss 920.04 | n100 0.443 | r10 0.378 | r20 0.348 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 183 | time: 18.33s | valid loss 919.94 | n100 0.442 | r10 0.376 | r20 0.348 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 184 | time: 18.29s | valid loss 919.92 | n100 0.442 | r10 0.377 | r20 0.347 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 185 | time: 18.44s | valid loss 919.90 | n100 0.443 | r10 0.378 | r20 0.347 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 186 | time: 18.39s | valid loss 919.79 | n100 0.442 | r10 0.376 | r20 0.347 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 187 | time: 18.45s | valid loss 919.82 | n100 0.443 | r10 0.377 | r20 0.347 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 188 | time: 18.44s | valid loss 919.77 | n100 0.444 | r10 0.379 | r20 0.348 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 189 | time: 18.42s | valid loss 919.64 | n100 0.442 | r10 0.377 | r20 0.346 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 190 | time: 18.39s | valid loss 919.62 | n100 0.443 | r10 0.377 | r20 0.348 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 191 | time: 18.43s | valid loss 919.61 | n100 0.443 | r10 0.378 | r20 0.348 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 192 | time: 18.44s | valid loss 919.52 | n100 0.442 | r10 0.375 | r20 0.347 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 193 | time: 18.36s | valid loss 919.45 | n100 0.443 | r10 0.376 | r20 0.346 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 194 | time: 18.42s | valid loss 919.43 | n100 0.444 | r10 0.377 | r20 0.347 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 195 | time: 18.44s | valid loss 919.40 | n100 0.444 | r10 0.380 | r20 0.349 | r50 0.406\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 196 | time: 18.31s | valid loss 919.35 | n100 0.443 | r10 0.376 | r20 0.348 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 197 | time: 18.40s | valid loss 919.28 | n100 0.443 | r10 0.376 | r20 0.346 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 198 | time: 18.37s | valid loss 919.25 | n100 0.443 | r10 0.376 | r20 0.347 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 199 | time: 18.44s | valid loss 919.21 | n100 0.443 | r10 0.378 | r20 0.347 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch 200 | time: 18.55s | valid loss 919.26 | n100 0.444 | r10 0.379 | r20 0.348 | r50 0.407\n","-----------------------------------------------------------------------------------------\n","=========================================================================================\n","| End of training | test loss 933.02 | n100 0.45 | r10 0.38 | r20 0.35 | r50 0.41\n","=========================================================================================\n"]}],"source":["for epoch in range(1, args.epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model, criterion, optimizer, is_VAE=False)\n","    val_loss, n100, r10, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=False)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n","            'n100 {:5.3f} | r10 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n","                epoch, time.time() - epoch_start_time, val_loss,\n","                n100, r10, r20, r50))\n","    print('-' * 89)\n","\n","    n_iter = epoch * len(range(0, N, args.batch_size))\n","\n","\n","    # Save the model if the n100 is the best we've seen so far.\n","    if r10 > best_r10:    #n100 > best_n100\n","        with open(dae_path, 'wb') as f:\n","            torch.save(model, f)\n","        best_r10 = r10    #best_n100 = n100\n","\n","\n","\n","# Load the best saved model.\n","with open(dae_path, 'rb') as f:\n","    model = torch.load(f)\n","\n","# Run on test data.\n","test_loss, n100, r10, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=False)\n","print('=' * 89)\n","print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r10 {:4.2f} | r20 {:4.2f} | '\n","        'r50 {:4.2f}'.format(test_loss, n100, r10, r20, r50))\n","print('=' * 89)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"o1QjCbMBXw4v"},"source":["## 7. MultiVAE 테스트 (TODO)\n","\n","위의 MultiVAE 모델 코드, train, evaluate 함수를 완성하여, 아래 훈련 코드가 정상적으로 동작하도록 해보세요!"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"78zFFNzgbxa_"},"outputs":[],"source":["\n","# ###############################################################################\n","# # Load data\n","# ###############################################################################\n","\n","# loader = DataLoader(args.data_path)\n","\n","# n_items = loader.load_n_items()\n","# train_data = loader.load_data('train')\n","# vad_data_tr, vad_data_te = loader.load_data('validation')\n","# test_data_tr, test_data_te = loader.load_data('test')\n","\n","# N = train_data.shape[0]\n","# idxlist = list(range(N))\n","\n","# ###############################################################################\n","# # Build the model\n","# ###############################################################################\n","\n","# p_dims = [200, 600, n_items]\n","# model = MultiVAE(p_dims).to(device)\n","\n","# optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n","# criterion = loss_function_vae\n","\n","# ###############################################################################\n","# # Training code\n","# ###############################################################################\n","\n","# best_r10 = -np.inf  #best_n100 = -np.inf\n","# update_count = 0"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53128,"status":"ok","timestamp":1647338513780,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"WoUFwndCvvtp","outputId":"5aef1fa2-a616-4494-d48a-6c8997e3190c"},"outputs":[],"source":["# for epoch in range(1, args.epochs + 1):\n","#     epoch_start_time = time.time()\n","#     train(model, criterion, optimizer, is_VAE=True)\n","#     val_loss, n100, r10, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=True)\n","#     print('-' * 89)\n","#     print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n","#             'n100 {:5.3f} | r10 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n","#                 epoch, time.time() - epoch_start_time, val_loss,\n","#                 n100, r10, r20, r50))\n","#     print('-' * 89)\n","\n","#     n_iter = epoch * len(range(0, N, args.batch_size))\n","\n","\n","#     # Save the model if the n100 is the best we've seen so far.\n","#     if r10 > best_r10:    #n100 > best_n100\n","#         with open(vae_path, 'wb') as f:\n","#             torch.save(model, f)\n","#         best_r10 = r10    #best_n100 = n100\n","\n","\n","\n","# # Load the best saved model.\n","# with open(vae_path, 'rb') as f:\n","#     model = torch.load(f)\n","\n","# # Run on test data.\n","# test_loss, n100, r10, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=True)\n","# print('=' * 89)\n","# print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r10 {:4.2f} | r20 {:4.2f} | '\n","#         'r50 {:4.2f}'.format(test_loss, n100, r10, r20, r50))\n","# print('=' * 89)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 8. 제출 파일 생성"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["if not os.path.exists(args.submit_path):\n","    os.makedirs(args.submit_path)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n","\n","inference_data = numerize(raw_data, profile2id, show2id)\n","n_items = inference_data['sid'].nunique()"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["start_idx = inference_data['uid'].min()\n","end_idx = inference_data['uid'].max()\n","\n","rows_if, cols_if = inference_data['uid'] - start_idx, inference_data['sid']\n","\n","inference_sdata = sparse.csr_matrix((np.ones_like(rows_if), (rows_if, cols_if)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["###############################################################################\n","# Load the model\n","###############################################################################\n","\n","p_dims = [200, 600, n_items]\n","\n","dmodel = MultiDAE(p_dims).to(device)\n","with open(dae_path, 'rb') as f:\n","    dmodel = torch.load(f)\n","\n","# vmodel = MultiVAE(p_dims).to(device)\n","# with open(vae_path, 'rb') as f:\n","#     vmodel = torch.load(f)"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["###############################################################################\n","# Inference\n","###############################################################################\n","dmodel.eval()\n","# vmodel.eval()\n","\n","drecon_list = []\n","# vrecon_list = []\n","update_count = 0\n","e_idxlist = list(range(inference_sdata.shape[0]))\n","e_N = inference_sdata.shape[0]\n","\n","with torch.no_grad():\n","    for start_idx in range(0, e_N, args.batch_size):\n","        end_idx = min(start_idx + args.batch_size, e_N)\n","        data = inference_sdata[e_idxlist[start_idx:end_idx]]\n","        data_tensor = naive_sparse2tensor(data).to(device)\n","        feat1 = torch.FloatTensor(np.array([list(genre_arr)] * (end_idx - start_idx))).to(device)\n","        # VAE\n","        # if args.total_anneal_steps > 0:\n","        #     anneal = min(args.anneal_cap, \n","        #         1. * update_count / args.total_anneal_steps)\n","        # else:\n","        #     anneal = args.anneal_cap\n","        # vrecon_batch, mu, logvar = vmodel(data_tensor)\n","        # DAE\n","        drecon_batch = dmodel(data_tensor,[feat1])\n","\n","        drecon_batch = drecon_batch.cpu().numpy()\n","        drecon_batch[data.nonzero()] = -10  # -np.inf, 분포 분석을 위해 교체\n","        drecon_list.append(drecon_batch)\n","\n","        # vrecon_batch = vrecon_batch.cpu().numpy()\n","        # vrecon_batch[data.nonzero()] = -10  # -np.inf, 분포 분석을 위해 교체\n","        # vrecon_list.append(vrecon_batch)\n","        \n","drecon_list = np.concatenate(drecon_list)\n","# vrecon_list = np.concatenate(vrecon_list)"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# np.argsort: 작은 값부터 순서대로 인덱스 반환\n","dpred = [[], []]\n","for u, i in enumerate(drecon_list):\n","    dpred[0].append([u]*10)\n","    dpred[1].append(np.argsort(i)[-10:])\n","dpred[0] = np.concatenate(dpred[0])\n","dpred[1] = np.concatenate(dpred[1])\n","\n","# vpred = [[], []]\n","# for u, i in enumerate(vrecon_list):\n","#     vpred[0].append([u]*10)\n","#     vpred[1].append(np.argsort(i)[-10:])\n","# vpred[0] = np.concatenate(vpred[0])\n","# vpred[1] = np.concatenate(vpred[1])"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["dsubmit = pd.DataFrame(data={'ui': dpred[0], 'ii': dpred[1]}, columns=['ui', 'ii'])\n","# vsubmit = pd.DataFrame(data={'ui': vpred[0], 'ii': vpred[1]}, columns=['ui', 'ii'])"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["#유저, 아이템 디코딩(원래값으로 변환)\n","rshow2id = dict((i, sid) for (i, sid) in enumerate(unique_sid))\n","rprofile2id = dict((i, pid) for (i, pid) in enumerate(unique_uid))\n","def reverse_numerize(tp, rshow2id, rprofile2id):\n","    user = tp['ui'].apply(lambda x: rprofile2id[x])\n","    item = tp['ii'].apply(lambda x: rshow2id[x])\n","    return pd.DataFrame(data={'user': user, 'item': item}, columns=['user', 'item'])"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["dsubmit_df = reverse_numerize(dsubmit, rshow2id, rprofile2id)\n","# vsubmit_df = reverse_numerize(vsubmit, rshow2id, rprofile2id)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>132668</th>\n","      <td>11</td>\n","      <td>37386</td>\n","    </tr>\n","    <tr>\n","      <th>132669</th>\n","      <td>11</td>\n","      <td>4370</td>\n","    </tr>\n","    <tr>\n","      <th>132667</th>\n","      <td>11</td>\n","      <td>55995</td>\n","    </tr>\n","    <tr>\n","      <th>132666</th>\n","      <td>11</td>\n","      <td>3156</td>\n","    </tr>\n","    <tr>\n","      <th>132665</th>\n","      <td>11</td>\n","      <td>8861</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49275</th>\n","      <td>138493</td>\n","      <td>2174</td>\n","    </tr>\n","    <tr>\n","      <th>49276</th>\n","      <td>138493</td>\n","      <td>33615</td>\n","    </tr>\n","    <tr>\n","      <th>49277</th>\n","      <td>138493</td>\n","      <td>2011</td>\n","    </tr>\n","    <tr>\n","      <th>49279</th>\n","      <td>138493</td>\n","      <td>1270</td>\n","    </tr>\n","    <tr>\n","      <th>49278</th>\n","      <td>138493</td>\n","      <td>2012</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>313600 rows × 2 columns</p>\n","</div>"],"text/plain":["          user   item\n","132668      11  37386\n","132669      11   4370\n","132667      11  55995\n","132666      11   3156\n","132665      11   8861\n","...        ...    ...\n","49275   138493   2174\n","49276   138493  33615\n","49277   138493   2011\n","49279   138493   1270\n","49278   138493   2012\n","\n","[313600 rows x 2 columns]"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["dsubmit_df.sort_values(by='user')"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["dsubmit_df.to_csv(args.submit_path+\"multi-dae_submission_+genre.csv\", index=False)\n","# vsubmit_df.to_csv(args.submit_path+\"multi-vae_submission.csv\", index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 결과 분석"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["6807"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["len(drecon_batch[0])"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"data":{"text/plain":["(array([203.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,\n","          6.,  19.,  35.,  70., 128., 195., 268., 352., 389., 415., 480.,\n","        475., 464., 458., 415., 370., 337., 309., 321., 227., 199., 184.,\n","        142., 114.,  84.,  72.,  39.,  22.,  11.]),\n"," array([-1.00000000e+01, -9.59968185e+00, -9.19936466e+00, -8.79904652e+00,\n","        -8.39872932e+00, -7.99841118e+00, -7.59809303e+00, -7.19777536e+00,\n","        -6.79745770e+00, -6.39714003e+00, -5.99682236e+00, -5.59650421e+00,\n","        -5.19618654e+00, -4.79586887e+00, -4.39555073e+00, -3.99523306e+00,\n","        -3.59491539e+00, -3.19459772e+00, -2.79427981e+00, -2.39396191e+00,\n","        -1.99364424e+00, -1.59332645e+00, -1.19300866e+00, -7.92690873e-01,\n","        -3.92373085e-01,  7.94470310e-03,  4.08262491e-01,  8.08580279e-01,\n","         1.20889807e+00,  1.60921586e+00,  2.00953364e+00,  2.40985155e+00,\n","         2.81016922e+00,  3.21048689e+00,  3.61080480e+00,  4.01112270e+00,\n","         4.41144037e+00,  4.81175804e+00,  5.21207619e+00,  5.61239386e+00,\n","         6.01271152e+00]),\n"," <BarContainer object of 40 artists>)"]},"execution_count":61,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 1152x648 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.figure(figsize=(16,9))\n","plt.hist(drecon_batch[-1], 40)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1VL4sSegbzZXhsufJOGCrhcXKvctKSb8z","timestamp":1670817430675}],"toc_visible":true},"kernelspec":{"display_name":"Python 3.8.5 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":0}
