{"cells":[{"cell_type":"markdown","metadata":{"id":"sQG9hL8-UQUP"},"source":["# Multi-VAE\n","\n","이번 미션에서는 [Variational Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1802.05814)에서 제안된 Multi-VAE 기반의 협업 필터링을 구현해보도록 하겠습니다. 다양한 Auto-Encoder 기반의 협업필터링이 제안된 이후에, 가장 강력하다고 평가받는 VAE 기반의 협업 필터링을 이해하는 시간을 갖도록 하겠습니다.\n","\n","- 이 미션은 다음 [코드](https://github.com/younggyoseo/vae-cf-pytorch)를 기반으로 작성되었습니다. 바로 코드를 확인해보지 마시고, 최대한 직접 작성을 해보세요!\n","- 이 미션에서 중요한 부분은 모델 부분입니다. 데이터 전처리 부분은 가볍게 훑어 보시고, 모델 부분을 집중해주세요!\n","- 완성을 해야할 부분은 TODO로 표시가 되어있습니다."]},{"cell_type":"markdown","metadata":{"id":"J7CfnRw7U59C"},"source":["## 1. 초기 세팅"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11383,"status":"ok","timestamp":1670464079058,"user":{"displayName":"김강민","userId":"16082862873898795036"},"user_tz":-540},"id":"EWWEf1mPKdnX","outputId":"627a84be-0adc-4cf2-a9de-478c7e81cad1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pandas==1.0.1\n","  Downloading pandas-1.0.1-cp38-cp38-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 22.8 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.8/site-packages (from pandas==1.0.1) (2.8.2)\n","Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.0.1) (1.19.2)\n","Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas==1.0.1) (2020.5)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas==1.0.1) (1.15.0)\n","Installing collected packages: pandas\n","Successfully installed pandas-1.0.1\n"]}],"source":["## 전처리과정에서 pandas의 버전에 다르게 동작하는 경향이 보여, 이 미션에서는 아래 버전으로 사용하도록하겠습니다.\n","!pip install pandas==1.0.1"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bQj6k1mSbxaz"},"outputs":[],"source":["import argparse\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from scipy import sparse\n"]},{"cell_type":"markdown","metadata":{"id":"j3E2IJSMjO_6"},"source":["## 데이터 다운로드\n","이곳에 대회 사이트(AI Stages)에 있는 data의 URL을 입력해주세요. \n","- 데이터 URL은 변경될 수 있습니다.\n","- 예) `!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000176/data/data.tar.gz`"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4232,"status":"ok","timestamp":1647318082403,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"jJ1hFEoNA7OE","outputId":"b08804c0-9813-4949-f77d-961694e4cc3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-12-14 04:07:09--  https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000226/data/data.tar.gz\n","Resolving aistages-prod-server-public.s3.amazonaws.com (aistages-prod-server-public.s3.amazonaws.com)... 52.218.213.171, 52.92.192.169, 52.92.146.249, ...\n","Connecting to aistages-prod-server-public.s3.amazonaws.com (aistages-prod-server-public.s3.amazonaws.com)|52.218.213.171|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 33425907 (32M) [binary/octet-stream]\n","Saving to: ‘data.tar.gz’\n","\n","data.tar.gz         100%[===================>]  31.88M  8.76MB/s    in 3.6s    \n","\n","2022-12-14 04:07:13 (8.76 MB/s) - ‘data.tar.gz’ saved [33425907/33425907]\n","\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.dropbox.attrs'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.dropbox.attrs'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.dropbox.attrs'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.dropbox.attrs'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n"]}],"source":["!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000226/data/data.tar.gz\n","!tar -xf data.tar.gz"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1647318083899,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"xQ3W0udmbxa3","outputId":"d556fee8-e1e8-4365-9068-551ba45d1aed"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["## 각종 파라미터 세팅\n","parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n","\n","\n","parser.add_argument('--data', type=str, default='data/train/',\n","                    help='Movielens dataset location')\n","\n","parser.add_argument('--lr', type=float, default=1e-4,\n","                    help='initial learning rate')\n","parser.add_argument('--wd', type=float, default=0.00,\n","                    help='weight decay coefficient')\n","parser.add_argument('--batch_size', type=int, default=500,\n","                    help='batch size')\n","parser.add_argument('--epochs', type=int, default=20,\n","                    help='upper epoch limit')\n","parser.add_argument('--total_anneal_steps', type=int, default=200000,\n","                    help='the total number of gradient updates for annealing')\n","parser.add_argument('--anneal_cap', type=float, default=0.2,\n","                    help='largest annealing parameter')\n","parser.add_argument('--seed', type=int, default=1111,\n","                    help='random seed')\n","parser.add_argument('--cuda', action='store_true',\n","                    help='use CUDA')\n","parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n","                    help='report interval')\n","parser.add_argument('--save', type=str, default='model.pt',\n","                    help='path to save the final model')\n","args = parser.parse_args([])\n","\n","# Set the random seed manually for reproductibility.\n","torch.manual_seed(args.seed)\n","\n","#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n","if torch.cuda.is_available():\n","    args.cuda = True\n","\n","device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{"id":"7o1fvXqFWE_G"},"source":["## 2. 데이터 전처리\n","\n","이 부분에서 진행되는 과정은 저희가 일반적으로 알고있는 MovieLens (user, item, timestamp)데이터를 전처리하는 과정입니다. 전처리 과정의 다양한 옵션들을 구성하기 위해 약간 복잡하게 되었지만, \n","결과적으로는, 유저들의 특정한 아이템들을 따로 분리를 해서, 그 분리된 값을 모델이 예측할 수 있냐를 확인하기 위한 전처리 과정이라고 보시면 되겠습니다.\n","실제로 나오는 데이터셋을 확인하면 더욱 이해가 빠를것입니다."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cgvNoy1Ybxa6"},"outputs":[],"source":["import os\n","import pandas as pd\n","from scipy import sparse\n","import numpy as np\n","\n","def get_count(tp, id):\n","    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n","    count = playcount_groupbyid.size()\n","\n","    return count\n","\n","# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상) \n","# 데이터만을 추출할 때 사용하는 함수입니다.\n","# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n","def filter_triplets(tp, min_uc=5, min_sc=0):\n","    if min_sc > 0:\n","        itemcount = get_count(tp, 'item')\n","        tp = tp[tp['item'].isin(itemcount.index[itemcount >= min_sc])]\n","\n","    if min_uc > 0:\n","        usercount = get_count(tp, 'user')\n","        tp = tp[tp['user'].isin(usercount.index[usercount >= min_uc])]\n","\n","    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n","    return tp, usercount, itemcount\n","\n","#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n","#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n","#확인하기 위함입니다.\n","def split_train_test_proportion(data, test_prop=0.2):\n","    # User Split\n","    data_grouped_by_user = data.groupby('user')\n","    tr_list, te_list = list(), list()\n","\n","    np.random.seed(98765)\n","    \n","    for _, group in data_grouped_by_user:\n","        n_items_u = len(group)\n","        \n","        if n_items_u >= 5:\n","            idx = np.zeros(n_items_u, dtype='bool')\n","            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n","            \n","            # 8:2 Split -> logical_not : train, else: test\n","            tr_list.append(group[np.logical_not(idx)])\n","            te_list.append(group[idx])\n","        \n","        else:\n","            tr_list.append(group)\n","    \n","    data_tr = pd.concat(tr_list)\n","    data_te = pd.concat(te_list)\n","\n","    return data_tr, data_te\n","\n","def numerize(tp, profile2id, show2id):\n","    uid = tp['user'].apply(lambda x: profile2id[x])\n","    sid = tp['item'].apply(lambda x: show2id[x])\n","    \n","    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4637,"status":"ok","timestamp":1647318092923,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"fVFoRHrmVQsp","outputId":"bb4178bc-0dcc-454b-eddb-10f83179f778"},"outputs":[],"source":["print(\"Load and Preprocess Movielens dataset\")\n","# Load Data\n","DATA_DIR = args.data\n","raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n","print(\"원본 데이터\\n\", raw_data)\n","\n","# Filter Data\n","raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=0)\n","#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n","print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data)\n","\n","print(\"유저별 리뷰수\\n\",user_activity)\n","print(\"아이템별 리뷰수\\n\",item_popularity)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1647318093321,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"7T1dTsWUrffP","outputId":"c3f79dfb-8854-4894-bd36-dc07d5f9ee93"},"outputs":[],"source":["# Shuffle User Indices\n","unique_uid = user_activity.index\n","print(\"(BEFORE) unique_uid:\",unique_uid)\n","print(\"----\" * 30)\n","print()\n","np.random.seed(98765)\n","idx_perm = np.random.permutation(unique_uid.size)\n","unique_uid = unique_uid[idx_perm]\n","print(\"(AFTER) unique_uid:\",unique_uid)\n","\n","n_users = unique_uid.size #31360\n","n_heldout_users = 3000\n","\n","\n","# Split Train/Validation/Test User Indices\n","tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n","vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n","te_users = unique_uid[(n_users - n_heldout_users):]\n","\n","#주의: 데이터의 수가 아닌 사용자의 수입니다!\n","print(\"----\" * 30)\n","print()\n","print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n","print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n","print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20754,"status":"ok","timestamp":1647318114955,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"3yBsRCRqtPz6","outputId":"1f8c7e6e-6ff0-42d6-bb9a-367dfc5d16bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Done!\n"]}],"source":["##훈련 데이터에 해당하는 아이템들\n","#Train에는 전체 데이터를 사용합니다.\n","train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n","\n","##아이템 ID item : profile2id, show2id\n","unique_sid = pd.unique(train_plays['item'])\n","\n","show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n","profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n","\n","## 폴더 생성\n","pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n","\n","if not os.path.exists(pro_dir):\n","    os.makedirs(pro_dir)\n","\n","with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n","    for sid in unique_sid:\n","        f.write('%s\\n' % sid)\n","\n","#Validation과 Test에는 input으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다. 8:2\n","vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n","vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n","vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n","\n","test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n","test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n","test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n","\n","\n","## train\n","train_data = numerize(train_plays, profile2id, show2id)\n","train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n","\n","## validation set 데이터와 정답\n","vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n","vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n","\n","vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n","vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n","\n","## test set 데이터와 정답\n","test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n","test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n","\n","test_data_te = numerize(test_plays_te, profile2id, show2id)\n","test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n","\n","print(\"Done!\")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1647318114956,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"jkdg2OkjqVUM","outputId":"393ce3ea-8f6a-4681-de4b-4c25eef547db"},"outputs":[{"name":"stdout","output_type":"stream","text":["           uid   sid\n","0        11825     0\n","1        11825     1\n","2        11825     2\n","3        11825     3\n","4        11825     4\n","...        ...   ...\n","5154466  10783   477\n","5154467  10783  1325\n","5154468  10783   331\n","5154469  10783   558\n","5154470  10783  1922\n","\n","[4168598 rows x 2 columns]\n","           uid   sid\n","376      26554   440\n","377      26554   741\n","378      26554  1407\n","379      26554   193\n","380      26554  1041\n","...        ...   ...\n","5153247  26934   760\n","5153248  26934   697\n","5153249  26934  3245\n","5153250  26934  1369\n","5153251  26934  3691\n","\n","[397924 rows x 2 columns]\n","           uid   sid\n","382      26554  3025\n","383      26554  1681\n","384      26554   201\n","399      26554  3190\n","401      26554  3301\n","...        ...   ...\n","5153233  26934   228\n","5153234  26934  1126\n","5153236  26934   235\n","5153242  26934   209\n","5153244  26934  1792\n","\n","[98001 rows x 2 columns]\n"]}],"source":["#데이터 셋 확인\n","print(train_data)\n","print(vad_data_tr)\n","print(vad_data_te)\n","# print(test_data_tr)\n","# print(test_data_te)"]},{"cell_type":"markdown","metadata":{"id":"SMiq9leyWWL1"},"source":["## 3. 데이터 로더 설정"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"nxUADr9ibxa8"},"outputs":[],"source":["class DataLoader():\n","    '''\n","    Load Movielens dataset\n","    '''\n","    def __init__(self, path):\n","        \n","        self.pro_dir = os.path.join(path, 'pro_sg')\n","        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n","\n","        self.n_items = self.load_n_items()\n","    \n","    def load_data(self, datatype='train'):\n","        if datatype == 'train':\n","            return self._load_train_data()\n","        elif datatype == 'validation':\n","            return self._load_tr_te_data(datatype)\n","        elif datatype == 'test':\n","            return self._load_tr_te_data(datatype)\n","        else:\n","            raise ValueError(\"datatype should be in [train, validation, test]\")\n","        \n","    def load_n_items(self):\n","        unique_sid = list()\n","        with open(os.path.join(self.pro_dir, 'unique_sid.txt'), 'r') as f:\n","            for line in f:\n","                unique_sid.append(line.strip())\n","        n_items = len(unique_sid)\n","        return n_items\n","    \n","    def _load_train_data(self):\n","        path = os.path.join(self.pro_dir, 'train.csv')\n","        \n","        tp = pd.read_csv(path)\n","        n_users = tp['uid'].max() + 1\n","\n","        rows, cols = tp['uid'], tp['sid']\n","        data = sparse.csr_matrix((np.ones_like(rows),\n","                                 (rows, cols)), dtype='float64',\n","                                 shape=(n_users, self.n_items))\n","        return data\n","    \n","    def _load_tr_te_data(self, datatype='test'):\n","        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n","        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n","\n","        tp_tr = pd.read_csv(tr_path)\n","        tp_te = pd.read_csv(te_path)\n","\n","        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n","        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n","\n","        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n","        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n","\n","        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n","                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n","        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n","                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n","        return data_tr, data_te"]},{"cell_type":"markdown","metadata":{"id":"6FHhwKqXWaUZ"},"source":["## 4. 모델정의\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"QYlGPJTYU0ii"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import numpy as np\n","\n","\n","#이미 완성된 MultiDAE의 코드를 참고하여 그 아래 MultiVAE의 코드를 완성해보세요!\n","class MultiDAE(nn.Module):\n","    \"\"\"\n","    Container module for Multi-DAE.\n","\n","    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n","    See Variational Autoencoders for Collaborative Filtering\n","    https://arxiv.org/abs/1802.05814\n","    \"\"\"\n","\n","    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n","        super(MultiDAE, self).__init__()\n","        self.p_dims = p_dims\n","        if q_dims:\n","            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n","            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n","            self.q_dims = q_dims\n","        else:\n","            self.q_dims = p_dims[::-1]\n","\n","        self.dims = self.q_dims + self.p_dims[1:]\n","        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n","        self.drop = nn.Dropout(dropout)\n","        \n","        self.init_weights()\n","    \n","    def forward(self, input):\n","        h = F.normalize(input)\n","        h = self.drop(h)\n","\n","        for i, layer in enumerate(self.layers):\n","            h = layer(h)\n","            if i != len(self.layers) - 1:\n","                h = F.tanh(h)\n","        return h\n","\n","    def init_weights(self):\n","        for layer in self.layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","\n","\n","\n","#TODO1\n","# 다양한 VAE의 코드를 다음 코드를 확인한 뒤에, 아래코드에 맞춰서 직접 작성해보는 연습을 해보세요!\n","# https://github.com/AntixK/PyTorch-VAE\n","class MultiVAE(nn.Module):\n","    \"\"\"\n","    Container module for Multi-VAE.\n","\n","    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n","    See Variational Autoencoders for Collaborative Filtering\n","    https://arxiv.org/abs/1802.05814\n","    \"\"\"\n","\n","    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n","        super(MultiVAE, self).__init__()\n","        self.p_dims = p_dims\n","        if q_dims:\n","            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n","            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n","            self.q_dims = q_dims\n","        else:\n","            self.q_dims = p_dims[::-1]\n","\n","        # Last dimension of q- network is for mean and variance\n","        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n","        \n","        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n","        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n","        \n","        self.drop = nn.Dropout(dropout)\n","        self.init_weights()\n","    \n","    def forward(self, input):\n","        mu, logvar = self.encode(input)\n","        z = self.reparameterize(mu, logvar)\n","        \n","        return self.decode(z), mu, logvar\n","        # #TODO2\n","        # return None\n","    \n","    def encode(self, input):\n","        h = F.normalize(input)\n","        h = self.drop(h)\n","        \n","        for i, layer in enumerate(self.q_layers):\n","            h = layer(h)\n","            if i != len(self.q_layers) - 1:\n","                h = F.tanh(h)\n","            else:\n","                mu = h[:, :self.q_dims[-1]]\n","                logvar = h[:, self.q_dims[-1]:]\n","        return mu, logvar\n","        # h = F.normalize(input)\n","        # h = self.drop(h)\n","\n","        # for i, layer in enumerate(self.q_layers):\n","        #   #TODO3\n","        #   mu=None\n","        #   logvar=None\n","        #   pass\n","        # return mu, logvar\n","\n","    def reparameterize(self, mu, logvar):\n","        if self.training:\n","            std = torch.exp(0.5 * logvar)\n","            eps = torch.randn_like(std)\n","            return eps.mul(std).add_(mu)\n","        else:\n","            return mu\n","    \n","    def decode(self, z):\n","        h = z\n","        for i, layer in enumerate(self.p_layers):\n","            h = layer(h)\n","            if i != len(self.p_layers) - 1:\n","                h = F.tanh(h)\n","        return h\n","        # h = z\n","        # for i, layer in enumerate(self.p_layers):\n","        #     #TODO4\n","        #     pass\n","        # return h\n","\n","    def init_weights(self):\n","        for layer in self.q_layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","        \n","        for layer in self.p_layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","\n","\n","\n","def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n","    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n","    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n","\n","    return BCE + anneal * KLD\n","\n","def loss_function_dae(recon_x, x):\n","    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n","    return BCE\n","\n","\n","\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"7nEfVTktbxa8"},"outputs":[],"source":["\n","def sparse2torch_sparse(data):\n","    \"\"\"\n","    Convert scipy sparse matrix to torch sparse tensor with L2 Normalization\n","    This is much faster than naive use of torch.FloatTensor(data.toarray())\n","    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n","    \"\"\"\n","    samples = data.shape[0]\n","    features = data.shape[1]\n","    coo_data = data.tocoo()\n","    indices = torch.LongTensor([coo_data.row, coo_data.col])\n","    row_norms_inv = 1 / np.sqrt(data.sum(1))\n","    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n","    values = np.array([row2val[r] for r in coo_data.row])\n","    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n","    return t\n","\n","def naive_sparse2tensor(data):\n","    return torch.FloatTensor(data.toarray())\n","\n","\n","def train(model, criterion, optimizer, is_VAE = False):\n","    # Turn on training mode\n","    model.train()\n","    train_loss = 0.0\n","    start_time = time.time()\n","    global update_count\n","\n","    np.random.shuffle(idxlist)\n","    \n","    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n","        end_idx = min(start_idx + args.batch_size, N)\n","        data = train_data[idxlist[start_idx:end_idx]]\n","        data = naive_sparse2tensor(data).to(device)\n","        optimizer.zero_grad()\n","\n","        if is_VAE:\n","          if args.total_anneal_steps > 0:\n","              anneal = min(args.anneal_cap, \n","                              1. * update_count / args.total_anneal_steps)\n","          else:\n","              anneal = args.anneal_cap\n","              \n","          optimizer.zero_grad()\n","          recon_batch, mu, logvar = model(data)\n","          \n","          loss = criterion(recon_batch, data, mu, logvar, anneal)\n","          #TODO\n","          #model에 입력 출력 코드를 작성해주세요\n","          #loss 함수를 설정해주세요\n","        else:\n","          recon_batch = model(data)\n","          loss = criterion(recon_batch, data)\n","\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","\n","        update_count += 1\n","\n","        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n","                    'loss {:4.2f}'.format(\n","                        epoch, batch_idx, len(range(0, N, args.batch_size)),\n","                        elapsed * 1000 / args.log_interval,\n","                        train_loss / args.log_interval))\n","            \n","\n","            start_time = time.time()\n","            train_loss = 0.0\n","\n","\n","def evaluate(model, criterion, data_tr, data_te, is_VAE=False):\n","    # Turn on evaluation mode\n","    model.eval()\n","    total_loss = 0.0\n","    global update_count\n","    e_idxlist = list(range(data_tr.shape[0]))\n","    e_N = data_tr.shape[0]\n","    n100_list = []\n","    r10_list = []\n","    r20_list = []\n","    r50_list = []\n","    \n","    with torch.no_grad():\n","        for start_idx in range(0, e_N, args.batch_size):\n","            end_idx = min(start_idx + args.batch_size, N)\n","            data = data_tr[e_idxlist[start_idx:end_idx]]\n","            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n","\n","            data_tensor = naive_sparse2tensor(data).to(device)\n","            if is_VAE :\n","              if args.total_anneal_steps > 0:\n","                  anneal = min(args.anneal_cap, \n","                                1. * update_count / args.total_anneal_steps)\n","              else:\n","                  anneal = args.anneal_cap\n","               \n","              recon_batch, mu, logvar = model(data_tensor)\n","\n","              loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n","              #TODO\n","              #model에 입력 출력 코드를 작성해주세요\n","              #loss 함수를 설정해주세요\n","\n","            else :\n","              recon_batch = model(data_tensor)\n","              loss = criterion(recon_batch, data_tensor)\n","\n","            total_loss += loss.item()\n","\n","            # Exclude examples from training set\n","            recon_batch = recon_batch.cpu().numpy()\n","            recon_batch[data.nonzero()] = -np.inf\n","\n","            n100 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 100)\n","            r10 = Recall_at_k_batch(recon_batch, heldout_data, 10)\n","            r20 = Recall_at_k_batch(recon_batch, heldout_data, 20)\n","            r50 = Recall_at_k_batch(recon_batch, heldout_data, 50)\n","\n","            n100_list.append(n100)\n","            r10_list.append(r10)\n","            r20_list.append(r20)\n","            r50_list.append(r50)\n"," \n","    total_loss /= len(range(0, e_N, args.batch_size))\n","    n100_list = np.concatenate(n100_list)\n","    r10_list = np.concatenate(r10_list)\n","    r20_list = np.concatenate(r20_list)\n","    r50_list = np.concatenate(r50_list)\n","\n","    return total_loss, np.mean(n100_list), np.mean(r10_list), np.mean(r20_list), np.mean(r50_list)\n"]},{"cell_type":"markdown","metadata":{"id":"JOsCJbb_X9gl"},"source":["## Metric 정의"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"zxNtit6vbxa-"},"outputs":[],"source":["import bottleneck as bn\n","import numpy as np\n","\n","def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n","    '''\n","    Normalized Discounted Cumulative Gain@k for binary relevance\n","    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n","    '''\n","    batch_users = X_pred.shape[0]\n","    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n","    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n","                       idx_topk_part[:, :k]]\n","    idx_part = np.argsort(-topk_part, axis=1)\n","\n","    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n","\n","    tp = 1. / np.log2(np.arange(2, k + 2))\n","\n","    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n","                         idx_topk].toarray() * tp).sum(axis=1)\n","    IDCG = np.array([(tp[:min(n, k)]).sum()\n","                     for n in heldout_batch.getnnz(axis=1)])\n","    return DCG / IDCG\n","\n","\n","def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n","    batch_users = X_pred.shape[0]\n","\n","    idx = bn.argpartition(-X_pred, k, axis=1)\n","    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n","    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n","\n","    X_true_binary = (heldout_batch > 0).toarray()\n","    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n","        np.float32)\n","    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n","    return recall"]},{"cell_type":"markdown","metadata":{"id":"cDD7lD7sHcnH"},"source":["## MultiDAE 테스트"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"WLYyTwToX4fm"},"outputs":[],"source":["\n","###############################################################################\n","# Load data\n","###############################################################################\n","\n","loader = DataLoader(args.data)\n","\n","n_items = loader.load_n_items()\n","train_data = loader.load_data('train')\n","vad_data_tr, vad_data_te = loader.load_data('validation')\n","test_data_tr, test_data_te = loader.load_data('test')\n","\n","N = train_data.shape[0]\n","idxlist = list(range(N))\n","\n","###############################################################################\n","# Build the model\n","###############################################################################\n","\n","p_dims = [200, 600, n_items]\n","model = MultiDAE(p_dims).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n","criterion = loss_function_dae\n","\n","###############################################################################\n","# Training code\n","###############################################################################\n","\n","best_n100 = -np.inf\n","update_count = 0"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50098,"status":"ok","timestamp":1647318176188,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"6rOEDs2Lbxa-","outputId":"6fb9eb56-26a4-45aa-d867-84dacf7b1e0a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"name":"stdout","output_type":"stream","text":["-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 2.00s | valid loss 998.74 | n100 0.293 | r10 0.233 | r20 0.216 | r50 0.268\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 2.02s | valid loss 971.16 | n100 0.339 | r10 0.271 | r20 0.250 | r50 0.310\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 2.00s | valid loss 957.21 | n100 0.366 | r10 0.299 | r20 0.276 | r50 0.335\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 2.00s | valid loss 950.08 | n100 0.378 | r10 0.311 | r20 0.288 | r50 0.346\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 2.12s | valid loss 943.56 | n100 0.389 | r10 0.319 | r20 0.295 | r50 0.357\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 2.08s | valid loss 939.42 | n100 0.395 | r10 0.325 | r20 0.302 | r50 0.364\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 1.98s | valid loss 935.77 | n100 0.403 | r10 0.332 | r20 0.307 | r50 0.371\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 1.98s | valid loss 932.28 | n100 0.406 | r10 0.333 | r20 0.310 | r50 0.376\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 2.01s | valid loss 929.43 | n100 0.411 | r10 0.338 | r20 0.314 | r50 0.381\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 2.02s | valid loss 927.03 | n100 0.417 | r10 0.346 | r20 0.321 | r50 0.385\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  11 | time: 1.96s | valid loss 925.33 | n100 0.421 | r10 0.352 | r20 0.325 | r50 0.389\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  12 | time: 2.07s | valid loss 923.09 | n100 0.424 | r10 0.352 | r20 0.328 | r50 0.392\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  13 | time: 2.08s | valid loss 921.25 | n100 0.425 | r10 0.355 | r20 0.329 | r50 0.394\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  14 | time: 2.06s | valid loss 919.45 | n100 0.428 | r10 0.356 | r20 0.330 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  15 | time: 2.04s | valid loss 917.85 | n100 0.427 | r10 0.353 | r20 0.331 | r50 0.396\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  16 | time: 1.97s | valid loss 916.36 | n100 0.430 | r10 0.355 | r20 0.330 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  17 | time: 2.07s | valid loss 914.89 | n100 0.430 | r10 0.358 | r20 0.333 | r50 0.399\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  18 | time: 2.00s | valid loss 913.62 | n100 0.433 | r10 0.359 | r20 0.336 | r50 0.401\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  19 | time: 2.05s | valid loss 912.31 | n100 0.433 | r10 0.361 | r20 0.337 | r50 0.402\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  20 | time: 2.04s | valid loss 911.07 | n100 0.435 | r10 0.365 | r20 0.339 | r50 0.404\n","-----------------------------------------------------------------------------------------\n","=========================================================================================\n","| End of training | test loss 898.13 | n100 0.44| r10 0.36 | r20 0.34 | r50 0.41\n","=========================================================================================\n"]}],"source":["for epoch in range(1, args.epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model, criterion, optimizer, is_VAE=False)\n","    val_loss, n100, r10, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=False)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n","            'n100 {:5.3f} | r10 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n","                epoch, time.time() - epoch_start_time, val_loss,\n","                n100, r10, r20, r50))\n","    print('-' * 89)\n","\n","    n_iter = epoch * len(range(0, N, args.batch_size))\n","\n","\n","    # Save the model if the n100 is the best we've seen so far.\n","    if n100 > best_n100:\n","        with open(args.save, 'wb') as f:\n","            torch.save(model, f)\n","        best_n100 = n100\n","\n","\n","\n","# Load the best saved model.\n","with open(args.save, 'rb') as f:\n","    model = torch.load(f)\n","\n","# Run on test data.\n","test_loss, n100,r10, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=False)\n","print('=' * 89)\n","print('| End of training | test loss {:4.2f} | n100 {:4.2f}| r10 {:4.2f} | r20 {:4.2f} | '\n","        'r50 {:4.2f}'.format(test_loss, n100, r10, r20, r50))\n","print('=' * 89)"]},{"cell_type":"markdown","metadata":{"id":"o1QjCbMBXw4v"},"source":["## MultiVAE 테스트 (TODO)\n","\n","- 위의 MultiVAE 모델 코드, train, evaluate 함수를 완성하여, 아래 훈련 코드가 정상적으로 동작하도록 해보세요!\n","- 다양한 VAE의 코드를 다음 코드를 확인한 뒤에, 아래코드에 맞춰서 직접 작성해보는 연습을 해보세요!\n","  - https://github.com/AntixK/PyTorch-VAE\n","- 완성해야할 함수\n","  - MultiVAE class\n","    - forward\n","    - encode\n","    - decode\n","  - train\n","  - evaluate"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4941,"status":"ok","timestamp":1646922488386,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"78zFFNzgbxa_","outputId":"2d6d4723-d2db-4edc-b11b-a64b9ea95943"},"outputs":[],"source":["\n","###############################################################################\n","# Load data\n","###############################################################################\n","\n","loader = DataLoader(args.data)\n","\n","n_items = loader.load_n_items()\n","train_data = loader.load_data('train')\n","vad_data_tr, vad_data_te = loader.load_data('validation')\n","test_data_tr, test_data_te = loader.load_data('test')\n","\n","N = train_data.shape[0]\n","idxlist = list(range(N))\n","\n","###############################################################################\n","# Build the model\n","###############################################################################\n","\n","p_dims = [200, 600, n_items]\n","model = MultiVAE(p_dims).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n","criterion = loss_function_vae\n","\n","###############################################################################\n","# Training code\n","###############################################################################\n","\n","best_n100 = -np.inf\n","update_count = 0"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":7,"status":"error","timestamp":1646922488389,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"WoUFwndCvvtp","outputId":"4e50e9d7-8317-4d4f-8449-d384176378b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 1.91s | valid loss 1024.67 | n100 0.266 | r10 0.208| r20 0.195 | r50 0.241\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 2.02s | valid loss 981.77 | n100 0.317 | r10 0.255| r20 0.237 | r50 0.292\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 2.03s | valid loss 969.82 | n100 0.340 | r10 0.275| r20 0.254 | r50 0.311\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 2.09s | valid loss 959.61 | n100 0.361 | r10 0.293| r20 0.272 | r50 0.332\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 1.90s | valid loss 953.58 | n100 0.371 | r10 0.302| r20 0.279 | r50 0.340\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 1.95s | valid loss 946.13 | n100 0.386 | r10 0.312| r20 0.294 | r50 0.356\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 1.99s | valid loss 943.37 | n100 0.389 | r10 0.318| r20 0.296 | r50 0.360\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 2.03s | valid loss 940.67 | n100 0.394 | r10 0.324| r20 0.301 | r50 0.363\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 1.96s | valid loss 937.94 | n100 0.398 | r10 0.325| r20 0.303 | r50 0.367\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 1.87s | valid loss 935.51 | n100 0.405 | r10 0.333| r20 0.310 | r50 0.374\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  11 | time: 2.01s | valid loss 933.46 | n100 0.410 | r10 0.339| r20 0.314 | r50 0.377\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  12 | time: 2.01s | valid loss 931.65 | n100 0.410 | r10 0.336| r20 0.314 | r50 0.380\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  13 | time: 2.02s | valid loss 929.86 | n100 0.412 | r10 0.337| r20 0.315 | r50 0.382\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  14 | time: 2.03s | valid loss 928.45 | n100 0.417 | r10 0.346| r20 0.320 | r50 0.384\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  15 | time: 2.01s | valid loss 927.20 | n100 0.418 | r10 0.345| r20 0.320 | r50 0.388\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  16 | time: 2.03s | valid loss 926.16 | n100 0.418 | r10 0.345| r20 0.322 | r50 0.389\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  17 | time: 2.00s | valid loss 925.39 | n100 0.421 | r10 0.346| r20 0.323 | r50 0.391\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  18 | time: 2.11s | valid loss 924.35 | n100 0.420 | r10 0.345| r20 0.320 | r50 0.391\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  19 | time: 2.10s | valid loss 923.49 | n100 0.424 | r10 0.348| r20 0.324 | r50 0.392\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  20 | time: 2.03s | valid loss 922.58 | n100 0.424 | r10 0.349| r20 0.324 | r50 0.394\n","-----------------------------------------------------------------------------------------\n","=========================================================================================\n","| End of training | test loss 909.43 | n100 0.43 | r10 0.35| r20 0.33 | r50 0.39\n","=========================================================================================\n"]}],"source":["for epoch in range(1, args.epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model, criterion, optimizer, is_VAE=True)\n","    val_loss, n100, r10, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=True)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n","            'n100 {:5.3f} | r10 {:5.3f}| r20 {:5.3f} | r50 {:5.3f}'.format(\n","                epoch, time.time() - epoch_start_time, val_loss,\n","                n100, r10, r20, r50))\n","    print('-' * 89)\n","\n","    n_iter = epoch * len(range(0, N, args.batch_size))\n","\n","\n","    # Save the model if the n100 is the best we've seen so far.\n","    if n100 > best_n100:\n","        with open(args.save, 'wb') as f:\n","            torch.save(model, f)\n","        best_n100 = n100\n","\n","\n","\n","# Load the best saved model.\n","with open(args.save, 'rb') as f:\n","    model = torch.load(f)\n","\n","# Run on test data.\n","test_loss, n100, r10,  r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=True)\n","print('=' * 89)\n","print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r10 {:4.2f}| r20 {:4.2f} | '\n","        'r50 {:4.2f}'.format(test_loss, n100, r10, r20, r50))\n","print('=' * 89)"]},{"cell_type":"markdown","metadata":{"id":"yc8QsKFkJdHL"},"source":["### **콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.8.5 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":0}
