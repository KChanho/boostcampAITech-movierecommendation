{"cells":[{"cell_type":"markdown","metadata":{"id":"SErkT_jPdGp6"},"source":["# DeepFM\n","\n","이번 실습에서는 DeepFM 모델을 이해하고 구현해보겠습니다.  \n","\n","DeepFM 모델은 Factorization machines와 neural network를 합친 모델로, Wide & Deep model과 유사하지만, feature engineering이 필요하지 않다는 특징을 가지고 있습니다.  \n","<br/>\n","사용자가 영화에 대해 Rating한 데이터, 영화의 장르 데이터를 이용하여 Train/Test data를 생성한 다음, Train data로 학습한 모델을 Test data에 대해 평가해봅니다.   \n","사용한 데이터는 Implicit feedback data로, 사용자가 시청한 영화(Positive instances)는 rating = 1로 기록됩니다. 따라서 시청하지 않은 영화에 대해 각 유저별로 Negative instances sampling을 진행합니다.   \n","<br/>\n","**구현에 앞서, DeepFM 논문을 꼭 읽어보시길 권장합니다.**\n","\n","* 참고  \n","    - DeepFM: A Factorization-Machine based Neural Network for CTR Prediction (https://arxiv.org/pdf/1703.04247.pdf)  \n","    - Wide & Deep Learning for Recommender Systems (https://arxiv.org/pdf/1606.07792.pdf)\n","    - Factorization Machines (https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694074)\n","    - https://d2l.ai/chapter_recommender-systems/deepfm.html"]},{"cell_type":"markdown","metadata":{"id":"jvcgI1nQdGp8"},"source":["# Modules"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"hJSpT7rFdGp8"},"outputs":[],"source":["import csv\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset"]},{"cell_type":"markdown","metadata":{"id":"FeUz2WmydGp9"},"source":["# Data preprocessing\n","0. Dataset 다운로드  \n","<br/>\n","1. Rating df 생성  \n","rating 데이터(train_ratings.csv)를 불러와 [user, item, rating]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n","<br/>\n","2. Genre df 생성   \n","genre 정보가 담긴 데이터(genres.tsv)를 불러와 genre이름을 id로 변경하고, [item, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.    \n","<br/>\n","3. Negative instances 생성   \n","rating 데이터는 implicit feedback data(rating :0/1)로, positive instances로 구성되어 있습니다. 따라서 rating이 없는 item중 negative instances를 뽑아서 데이터에 추가하게 됩니다.   \n","<br/>\n","4. Join dfs   \n","rating df와 genre df를 join하여 [user, item, rating, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n","<br/>\n","5. zero-based index로 mapping   \n","Embedding을 위해서 user,item,genre를 zero-based index로 mapping합니다.\n","    - user : 0-31359\n","    - item : 0-6806\n","    - genre : 0-17  \n","<br/>\n","6. feature matrix X, label tensor y 생성   \n","[user, item, genre] 3개의 field로 구성된 feature matrix를 생성합니다.   \n","<br/>\n","7. data loader 생성"]},{"cell_type":"markdown","metadata":{"id":"ABiFIo3BkUI-"},"source":["## 데이터 다운로드\n","이곳에 대회 사이트(AI Stages)에 있는 data의 URL을 입력해주세요. \n","- 데이터 URL은 변경될 수 있습니다.\n","- 예) `!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000176/data/data.tar.gz`"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"elapsed":5,"status":"error","timestamp":1648178005180,"user":{"displayName":"Suhyeon Jo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OgPqosjpQIx10Ta9eTGlvRf7L-hBuT3wpZ-o=s64","userId":"13966273005387857802"},"user_tz":-540},"id":"yB1Na9htdGp-","outputId":"4182575e-5f95-4e03-bf09-2b9eb387d094"},"outputs":[],"source":["# 1. Rating df 생성\n","rating_data = \"/opt/ml/input/data/train/train_ratings.csv\"\n","\n","raw_rating_df = pd.read_csv(rating_data)\n","raw_rating_df\n","\n","# implict feedback을 만들기 위해서 rating column 추가\n","raw_rating_df['rating'] = 1.0 \n","# time은 사용하지 않기에 드랍\n","raw_rating_df.drop(['time'],axis=1,inplace=True)\n","\n","# 각각 user와 item의 set 만들기\n","users = set(raw_rating_df.loc[:, 'user'])\n","items = set(raw_rating_df.loc[:, 'item'])\n","\n","#2. Genre df 생성\n","genre_data = \"/opt/ml/input/data/train/genres.tsv\"\n","\n","raw_genre_df = pd.read_csv(genre_data, sep='\\t')\n","# 아이템별로 하나의 장르만 남게 드랍 ~ 최초로 나오는 것만\n","raw_genre_df = raw_genre_df.drop_duplicates(subset=['item'])\n","\n","# 인덱싱\n","genre_dict = {genre:i for i, genre in enumerate(set(raw_genre_df['genre']))}\n","raw_genre_df['genre']  = raw_genre_df['genre'].map(lambda x : genre_dict[x]) "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"stnVq1AFdGp-"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 31360/31360 [05:30<00:00, 94.90it/s] \n"]}],"source":["# 3. Negative instance 생성 ~ 현재 implict feedback은 positive밖에 없기에\n","\n","num_negative = 50   # negative sampling할 수\n","user_group_dfs = list(raw_rating_df.groupby('user')['item'])    # 유저-아이템 리스트\n","first_row = True\n","user_neg_dfs = pd.DataFrame()   # negative sampling 담을 데이터프레임\n","\n","for u, u_items in tqdm(user_group_dfs):\n","    # num_negative만큼, user-item에서 없는 아이템을 랜덤하게 추출\n","    u_items = set(u_items)\n","    i_user_neg_item = np.random.choice(list(items - u_items), num_negative, replace=False)\n","    \n","    # 그렇게 만들어진 negative sampling데이터를 합치기 ~ 처음 합쳐지는 경우엔 concat이 불가하니, 대체해서 사용\n","    i_user_neg_df = pd.DataFrame({'user': [u]*num_negative, 'item': i_user_neg_item, 'rating': [0]*num_negative})\n","    if first_row == True:\n","        user_neg_dfs = i_user_neg_df\n","        first_row = False\n","    else:\n","        user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)\n","\n","# 최종적으로 postive + negative 합치기 ~\n","raw_rating_df = pd.concat([raw_rating_df, user_neg_dfs], axis = 0, sort=False)\n","\n","# 4. genre와 rating merge\n","joined_rating_df = pd.merge(raw_rating_df, raw_genre_df, left_on='item', right_on='item', how='inner')\n","\n","# 5. user, item을 인덱싱, 이때 각각 unique한 feature set도 생성\n","users = list(set(joined_rating_df.loc[:,'user']))\n","users.sort()\n","items =  list(set((joined_rating_df.loc[:, 'item'])))\n","items.sort()\n","genres =  list(set((joined_rating_df.loc[:, 'genre'])))\n","genres.sort()\n","\n","# 즐거운 인덱싱\n","if len(users)-1 != max(users):\n","    users_dict = {users[i]: i for i in range(len(users))}\n","    joined_rating_df['user']  = joined_rating_df['user'].map(lambda x : users_dict[x])\n","    users = list(set(joined_rating_df.loc[:,'user']))\n","    \n","if len(items)-1 != max(items):\n","    items_dict = {items[i]: i for i in range(len(items))}\n","    joined_rating_df['item']  = joined_rating_df['item'].map(lambda x : items_dict[x])\n","    items =  list(set((joined_rating_df.loc[:, 'item'])))\n","\n","joined_rating_df = joined_rating_df.sort_values(by=['user'])\n","joined_rating_df.reset_index(drop=True, inplace=True)\n","# 변수 재지정\n","data = joined_rating_df\n","\n","# num 지정\n","n_data = len(data)\n","n_user = len(users)\n","n_item = len(items)\n","n_genre = len(genres)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"vx20eHxGdGp_"},"outputs":[],"source":["#6. 각 feature들에 대한 tensor 생성\n","user_col = torch.tensor(data.loc[:,'user'])\n","item_col = torch.tensor(data.loc[:,'item'])\n","genre_col = torch.tensor(data.loc[:,'genre'])\n","\n","# 각 텐서의 index가 고유한 값을 갖게 최대값을 순차적으로 더해주기 ~ indexing해줄때 해줘도 그만이다\n","offsets = [0, n_user, n_user+n_item]\n","for col, offset in zip([user_col, item_col, genre_col], offsets):\n","    col += offset\n","\n","# X, y 데이터 생성\n","X = torch.cat([user_col.unsqueeze(1), item_col.unsqueeze(1), genre_col.unsqueeze(1)], dim=1)\n","y = torch.tensor(list(data.loc[:,'rating']))\n","\n","\n","#7. data loader 생성\n","class RatingDataset(Dataset):\n","    def __init__(self, input_tensor, target_tensor):\n","        self.input_tensor = input_tensor.long()\n","        self.target_tensor = target_tensor.long()\n","\n","    def __getitem__(self, index):\n","        return self.input_tensor[index], self.target_tensor[index]\n","\n","    def __len__(self):\n","        return self.target_tensor.size(0)\n","\n","# 데이터 셋 만들기 이때, train ratio는 0.9\n","dataset = RatingDataset(X, y)\n","train_ratio = 0.9\n","\n","# 랜덤으로 split\n","train_size = int(train_ratio * len(data))\n","test_size = len(data) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","# loader에 태우기, 배치사이즈 조절 가능, train은 shuffle된 상태\n","train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"rfb7KEEMdGqA"},"source":["   # Model architecture (DeepFM)\n","   DeepFM 모델은 1) FM component와  2) Deep component가 병렬적으로 결합되어 있습니다. 구조는 다음과 같습니다.\n","<img src='https://drive.google.com/uc?id=1vwcxUJQTIsg5QH9CuH5PcUEfExhToUHR'>  \n","각 구조는 다음과 같습니다.  \n","   **1. FM component**  \n","       FM component는 우리가 아는 2-way Factorization machines(degree=2)입니다. FM은 variables 간의 interaction을 다음과 같이 모델링 합니다.   \n","     **<center> equation (1) </center>**\n","   $$\\hat{y}(x):=w_0 + \\sum_{i=1}^{n}w_ix_i + \\sum_{i=1}^{n}\\sum_{j=i+1}^{n}<\\mathbf{v}_i,\\mathbf{v}_j>x_ix_j$$   \n","   이때, 세번째 interaction term을 전개하여 다음과 같이 쓸 수 있습니다.(논문 참고)  \n","   구현 코드는 전개된 식을 바탕으로 합니다.   \n","     **<center> equation (2)> </center>**\n","   $$\\sum_{i=1}^{n}\\sum_{j=i+1}^{n}<\\mathbf{v}_i,\\mathbf{v}_j>x_ix_j = \\frac{1}{2}\\sum_{f=1}^{k}((\\sum_{i=1}^{n}v_{i,f}x_i)^2-\\sum_{i=1}^{n}v_{i,f}^2x_i^2)$$   \n","           \n","   **2. Deep component**  \n","       Deep component는 MLP Layers로 구성되어 있습니다.   \n","       구현 코드는 Input dimension이 30-20-10인 3 layer MLP 구조입니다.\n","  \n","   "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"oXlycCBkdGqA"},"outputs":[],"source":["class DeepFM(nn.Module):\n","    def __init__(self, input_dims, embedding_dim, mlp_dims, drop_rate=0.1):\n","        super(DeepFM, self).__init__()\n","        \n","        # MLP레이어 쌓기\n","        # input_dims = n_user + n_movie + n_genre ~ 모든 feature의 길이 합\n","        total_input_dim = int(sum(input_dims)) \n","\n","        # 초기 bias 설정 및 전체 최종 layer emb 설정\n","        self.bias = nn.Parameter(torch.zeros((1,)))\n","        self.fc = nn.Embedding(total_input_dim, 1)\n","        \n","        # 들어오는 n개의 피쳐들에 대해서 emb\n","        self.embedding = nn.Embedding(total_input_dim, embedding_dim) \n","        self.embedding_dim = len(input_dims) * embedding_dim\n","\n","        # MLP dim에 따라 layer 진행\n","        mlp_layers = []\n","        for i, dim in enumerate(mlp_dims):\n","            # mlp레이어 쌓기\n","            if i==0:\n","                # 첫 레이어에 대해서는 input으로 들어올 dim과 실제 mlp레이어 dim의 Linear\n","                mlp_layers.append(nn.Linear(self.embedding_dim, dim))\n","            else:\n","                # 그 이후 레이어에 대해서는 이전 레이어의 output과 실제 mlp레이어 dim의 Linear\n","                 mlp_layers.append(nn.Linear(mlp_dims[i-1], dim))    \n","            # activation layer 추가\n","            mlp_layers.append(nn.ReLU(True))                     \n","            # dropout\n","            mlp_layers.append(nn.Dropout(drop_rate))\n","            \n","        # 최종적으로 마지막에 마지막 레이어의 dim에서 1로 가는 Linear\n","        mlp_layers.append(nn.Linear(mlp_dims[-1], 1)) \n","        #  Sequential로 최종 정리\n","        self.mlp_layers = nn.Sequential(*mlp_layers)\n","\n","    def fm(self, x):\n","        \n","        # FM 레이어 쌓기\n","        # embding_dim으로 임베딩 된 값에 대해\n","        embed_x = self.embedding(x) \n","\n","        # bias 더 해주고\n","        fm_y = self.bias + torch.sum(self.fc(x), dim=1)\n","        # MSE loss\n","        # mse를 위해 square sum과 sum square로 설정 \n","        square_of_sum = torch.sum(embed_x, dim=1) ** 2        \n","        sum_of_square = torch.sum(embed_x ** 2, dim=1)\n","        fm_y += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n","        return fm_y\n","    \n","    def mlp(self, x):\n","        \n","        # MLP레이어 결과본\n","        # embding_dim으로 임베딩 된 값에 대해\n","        embed_x = self.embedding(x)\n","        \n","        # 사이즈 맞춰서 squeeze해주고 mlp_layer에 태우기\n","        inputs = embed_x.view(-1, self.embedding_dim)\n","        mlp_y = self.mlp_layers(inputs)\n","        return mlp_y\n","\n","    def forward(self, x):\n","        \n","        # 최종 forward\n","        # embding_dim으로 임베딩 된 값에 대해\n","        embed_x = self.embedding(x)\n","        \n","        # fm 레이어 결과값\n","        fm_y = self.fm(x).squeeze(1)\n","        \n","        # mlp 레이어 결과값\n","        mlp_y = self.mlp(x).squeeze(1)\n","        \n","        # concat후 sigmoid 태우기\n","        y = torch.sigmoid(fm_y + mlp_y)\n","        return y\n"]},{"cell_type":"markdown","metadata":{"id":"1mAwfPocdGqB"},"source":["# Training"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"RgBJPVuadGqB"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [14:03<00:00, 84.35s/it]\n"]}],"source":["# 디바이스 설정\n","device = torch.device('cuda')\n","# input_dims 설정\n","input_dims = [n_user, n_item, n_genre]\n","# 임베딩 dim 설정\n","embedding_dim = 10\n","# 모델설정\n","model = DeepFM(input_dims, embedding_dim, mlp_dims=[30, 20, 10]).to(device)\n","# loss 설정정\n","bce_loss = nn.BCELoss() # Binary Cross Entropy loss\n","# Optimizer 설정 및 epochs 설정\n","lr, num_epochs = 0.01, 10\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","for e in tqdm(range(num_epochs)) :\n","    # 각각 user,item,genre / rating\n","    for x, y in train_loader:\n","        x, y = x.to(device), y.to(device)\n","        model.train()\n","        optimizer.zero_grad()\n","        output = model(x)\n","        loss = bce_loss(output, y.float())\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"dIKWIOZ5dGqB"},"source":["# Evaluation\n","평가는 모델이 postive instance에 대해 0.5이상, negative instance에 대해 0.5미만의 값을 예측한 Accuracy를 측정하여 진행됩니다."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"igRcm9_6dGqC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final Acc : 90.46%\n"]}],"source":["# 평가하기 \n","correct_result_sum = 0\n","# test loader에 대해서 진행 이때 지표는 acc\n","for x, y in test_loader:\n","    x, y = x.to(device), y.to(device)\n","    model.eval()\n","    output = model(x)\n","    result = torch.round(output)\n","    correct_result_sum += (result == y).sum().float()\n","\n","acc = correct_result_sum/len(test_dataset)*100\n","print(\"Final Acc : {:.2f}%\".format(acc.item()))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# inf"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  7%|▋         | 2313/31360 [00:11<02:30, 193.22it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/opt/ml/input/sample_code/(미션-3) Factorization machines with PyTorch (DeepFM) (문제).ipynb 셀 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a57227d/opt/ml/input/sample_code/%28%EB%AF%B8%EC%85%98-3%29%20Factorization%20machines%20with%20PyTorch%20%28DeepFM%29%20%28%EB%AC%B8%EC%A0%9C%29.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# user, item, genre 데이터를 인코딩하여 학습한 모델에 맞는 값으로 변환\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a57227d/opt/ml/input/sample_code/%28%EB%AF%B8%EC%85%98-3%29%20Factorization%20machines%20with%20PyTorch%20%28DeepFM%29%20%28%EB%AC%B8%EC%A0%9C%29.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m i_user_col \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([u] \u001b[39m*\u001b[39m n_item)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a57227d/opt/ml/input/sample_code/%28%EB%AF%B8%EC%85%98-3%29%20Factorization%20machines%20with%20PyTorch%20%28DeepFM%29%20%28%EB%AC%B8%EC%A0%9C%29.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m i_item_col \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(raw_genre_df[\u001b[39m'\u001b[39;49m\u001b[39mitem\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m x : items_dict[x])\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a57227d/opt/ml/input/sample_code/%28%EB%AF%B8%EC%85%98-3%29%20Factorization%20machines%20with%20PyTorch%20%28DeepFM%29%20%28%EB%AC%B8%EC%A0%9C%29.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m i_genre_col \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(raw_genre_df[\u001b[39m'\u001b[39m\u001b[39mgenre\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a57227d/opt/ml/input/sample_code/%28%EB%AF%B8%EC%85%98-3%29%20Factorization%20machines%20with%20PyTorch%20%28DeepFM%29%20%28%EB%AC%B8%EC%A0%9C%29.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m col, offset \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m([i_user_col, i_item_col, i_genre_col], offsets):\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py:4540\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4465\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4466\u001b[0m \u001b[39mMap values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4467\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4537\u001b[0m \u001b[39mdtype: object\u001b[39;00m\n\u001b[1;32m   4538\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4539\u001b[0m new_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_values(arg, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m-> 4540\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(new_values, index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\u001b[39m.\u001b[39m__finalize__(\n\u001b[1;32m   4541\u001b[0m     \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmap\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4542\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py:472\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m--> 472\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39;49m\u001b[39mmode.data_manager\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    474\u001b[0m         data \u001b[39m=\u001b[39m SingleBlockManager\u001b[39m.\u001b[39mfrom_array(data, index)\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_config/config.py:263\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 263\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__func__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_config/config.py:135\u001b[0m, in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_option\u001b[39m(pat: \u001b[39mstr\u001b[39m, silent: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 135\u001b[0m     key \u001b[39m=\u001b[39m _get_single_key(pat, silent)\n\u001b[1;32m    137\u001b[0m     \u001b[39m# walk the nested dict\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     root, k \u001b[39m=\u001b[39m _get_root(key)\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_config/config.py:117\u001b[0m, in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_single_key\u001b[39m(pat: \u001b[39mstr\u001b[39m, silent: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m     keys \u001b[39m=\u001b[39m _select_options(pat)\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(keys) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    119\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m silent:\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_config/config.py:579\u001b[0m, in \u001b[0;36m_select_options\u001b[0;34m(pat)\u001b[0m\n\u001b[1;32m    572\u001b[0m     _deprecated_options[key] \u001b[39m=\u001b[39m DeprecatedOption(key, msg, rkey, removal_ver)\n\u001b[1;32m    575\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[39m# functions internal to the module\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_select_options\u001b[39m(pat: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m    580\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[39m    returns a list of keys matching `pat`\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \n\u001b[1;32m    583\u001b[0m \u001b[39m    if pat==\"all\", returns all registered options\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     \u001b[39m# short-circuit for exact key\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["u_list = []\n","i_list = []\n","ritems_dict = {v:k for k,v in items_dict.items()}\n","\n","for u, u_items in tqdm(user_group_dfs):\n","\n","    # 인코딩하기 전에 유저id 저장\n","    u_list.append([u]*10)\n","\n","    # user_group_dfs은 인코딩 이전 값이므로 사용하기 위해 인코딩 진행\n","    u = users_dict[u]\n","    u_items = set(u_items.map(lambda x : items_dict[x]))    # 나중에 본 것들 제외용\n","\n","    # user, item, genre 데이터를 인코딩하여 학습한 모델에 맞는 값으로 변환\n","    i_user_col = torch.tensor([u] * n_item)\n","    i_item_col = torch.tensor(raw_genre_df['item'].map(lambda x : items_dict[x]).values)\n","    i_genre_col = torch.tensor(raw_genre_df['genre'].values)\n","    for col, offset in zip([i_user_col, i_item_col, i_genre_col], offsets):\n","        col += offset\n","        \n","    X = torch.cat([i_user_col.unsqueeze(1), i_item_col.unsqueeze(1), i_genre_col.unsqueeze(1)], dim=1)\n","    X = X.to(device)\n","    with torch.no_grad():\n","        model.eval()\n","        output = model(X)\n","        output = output.cpu().detach().numpy()\n","        output[list(u_items)] = -np.inf   # 이미 본 아이템 제외\n","        result_batch = np.argsort(output[list(u_items)])[::-1][:10] # 역방향 -> 정방향으로 수정\n","        i_list.append(list(map(lambda x : ritems_dict[x], result_batch)))  # 아이템 디코딩, ndarray는 map()이 안돼서 다른 방법 찾음\n","    \n"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[],"source":["u_list = np.concatenate(u_list)\n","i_list = np.concatenate(i_list)\n","\n","submit_df = pd.DataFrame(data={'user': u_list, 'item': i_list}, columns=['user', 'item'])\n","print()\n"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["submit_df.to_csv('/opt/ml/input/sample_code/sub_fm_new.csv')"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"data":{"text/plain":["array([349,   6, 283,  77,   0,  47,   9,  22,  10, 116])"]},"execution_count":164,"metadata":{},"output_type":"execute_result"}],"source":["np.argsort(output[list(u_items)])[::-1][:10]"]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[{"data":{"text/plain":["array([   1, 2993,   22,   27,    6,  127, 3655, 3419, 3780, 2938])"]},"execution_count":166,"metadata":{},"output_type":"execute_result"}],"source":["np.argsort(output)[::-1][:10]"]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[{"data":{"text/plain":["array([   1, 2993,   22,   27,    6,  127, 3655, 3419, 3780, 2938])"]},"execution_count":167,"metadata":{},"output_type":"execute_result"}],"source":["np.argsort(output)[-10:][::-1]"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[{"data":{"text/plain":["0.99998283"]},"execution_count":135,"metadata":{},"output_type":"execute_result"}],"source":["float(9.9998283e-01)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":0}
